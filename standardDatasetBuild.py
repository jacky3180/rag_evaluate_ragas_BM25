"""
æ ‡å‡†æ•°æ®é›†æ„å»ºæ¨¡å—
ä½¿ç”¨Ragas APIæ„å»ºæ ‡å‡†æ•°æ®é›†
"""

import os
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Optional
from config import debug_print, verbose_print, info_print, error_print, QUIET_MODE
import asyncio
import aiohttp
import json
from read_chuck import DataLoader, TextProcessor, EvaluationConfig
from text_similarity import calculate_text_similarity
import logging
import openai
from dotenv import load_dotenv
from openpyxl import load_workbook, Workbook
from openpyxl.styles import Alignment
from openpyxl.utils import get_column_letter

# å¯¼å…¥ Ragas ç›¸å…³æ¨¡å—
from ragas import evaluate, SingleTurnSample
from ragas.metrics import (
    Faithfulness,
    AnswerRelevancy,
    ContextPrecision,
    ContextRecall,
    ContextRelevance
)
from ragas import EvaluationDataset
from ragas.llms import LangchainLLMWrapper
from langchain_openai import ChatOpenAI
from ragas.testset import TestsetGenerator

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class StandardDatasetBuilder:
    """æ ‡å‡†æ•°æ®é›†æ„å»ºå™¨"""
    
    def __init__(self, knowledge_doc_dir: str = "knowledgeDoc", 
                 standard_dataset_path: str = "standardDataset/standardDataset_build.xlsx"):
        self.knowledge_doc_dir = Path(knowledge_doc_dir)
        self.standard_dataset_path = Path(standard_dataset_path)
        
        # é…ç½®OpenAIå®¢æˆ·ç«¯
        self.openai_client = openai.OpenAI(
            api_key=os.getenv('OPENAI_API_KEY') or os.getenv('QWEN_API_KEY'),
            base_url=os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1')
        )
        
        # é…ç½® Langchain LLMï¼ˆä½¿ç”¨ç¨³å®šçš„é‡‡æ ·å‚æ•°ï¼‰
        # æ³¨æ„ï¼šQwen API è¦æ±‚å‚æ•°æ˜¾å¼æŒ‡å®šï¼Œä¸èƒ½ä½¿ç”¨ model_kwargs
        self.llm = ChatOpenAI(
            model=os.getenv('MODEL_NAME', 'qwen-plus'),
            api_key=os.getenv('OPENAI_API_KEY') or os.getenv('QWEN_API_KEY'),
            base_url=os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1'),
            temperature=0.0,  # é™ä½åˆ° 0.0 ä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º
            top_p=0.1,  # åªä»æœ€é«˜æ¦‚ç‡çš„ 10% token ä¸­é€‰æ‹©
            max_tokens=2000  # æœ€å¤§ç”Ÿæˆé•¿åº¦
        )
        
        # é…ç½® Ragas LLMï¼ˆä½¿ç”¨ç¨³å®šçš„é‡‡æ ·å‚æ•°ï¼‰
        # æ³¨æ„ï¼šQwen API è¦æ±‚å‚æ•°æ˜¾å¼æŒ‡å®šï¼Œä¸èƒ½ä½¿ç”¨ model_kwargs
        self.ragas_llm = LangchainLLMWrapper(
            ChatOpenAI(
                model=os.getenv('MODEL_NAME', 'qwen-plus'),
                api_key=os.getenv('OPENAI_API_KEY') or os.getenv('QWEN_API_KEY'),
                base_url=os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1'),
                temperature=0.0,  # é™ä½åˆ° 0.0 ä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º
                top_p=0.1,  # åªä»æœ€é«˜æ¦‚ç‡çš„ 10% token ä¸­é€‰æ‹©
                max_tokens=2000  # æœ€å¤§ç”Ÿæˆé•¿åº¦
            )
        )
        
    def load_knowledge_documents(self) -> List[Dict[str, Any]]:
        """
        åŠ è½½çŸ¥è¯†åº“æ–‡æ¡£
        
        Returns:
            List[Dict]: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£åŒ…å«è·¯å¾„ã€å†…å®¹ã€åˆ†å—ç­‰ä¿¡æ¯
        """
        if not self.knowledge_doc_dir.exists():
            logger.warning(f"çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨: {self.knowledge_doc_dir}")
            return []
        
        documents = []
        # åˆ›å»ºé…ç½®å¯¹è±¡
        config = EvaluationConfig(
            api_key=os.getenv('OPENAI_API_KEY', ''),
            api_base=os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1'),
            model_name=os.getenv('MODEL_NAME', 'qwen-plus')
        )
        text_processor = TextProcessor(config)
        
        for file_path in self.knowledge_doc_dir.iterdir():
            if file_path.is_file():
                try:
                    # è¯»å–æ–‡æ¡£å†…å®¹
                    with open(file_path, 'r', encoding='utf-8') as f:
                        doc_content = f.read()
                    
                    if doc_content:
                        # åˆ†å—å¤„ç†ï¼ˆä¿ç•™åŸå§‹æ–‡æ¡£å†…å®¹ï¼Œä¸æ¸…ç†æ ‡é¢˜ï¼‰
                        chunks = text_processor.split_text_into_chunks(doc_content)
                        documents.append({
                            'path': str(file_path),
                            'name': file_path.name,
                            'content': doc_content,
                            'chunks': chunks
                        })
                        logger.info(f"åŠ è½½æ–‡æ¡£: {file_path.name}, åˆ†å—æ•°: {len(chunks)}")
                except Exception as e:
                    logger.error(f"åŠ è½½æ–‡æ¡£å¤±è´¥ {file_path.name}: {e}")
        
        return documents
    
    
    def load_standard_dataset(self) -> Optional[pd.DataFrame]:
        """
        åŠ è½½æ ‡å‡†æ•°æ®é›†
        
        Returns:
            pd.DataFrame: æ ‡å‡†æ•°æ®é›†DataFrame
        """
        if not self.standard_dataset_path.exists():
            logger.error(f"æ ‡å‡†æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {self.standard_dataset_path}")
            return None
        
        try:
            df = pd.read_excel(self.standard_dataset_path)
            
            # ç¡®ä¿reference_contextså’Œreferenceåˆ—çš„æ•°æ®ç±»å‹ä¸ºå­—ç¬¦ä¸²
            if 'reference_contexts' in df.columns:
                df['reference_contexts'] = df['reference_contexts'].astype(str)
            if 'reference' in df.columns:
                df['reference'] = df['reference'].astype(str)
            
            logger.info(f"åŠ è½½æ ‡å‡†æ•°æ®é›†: {len(df)} è¡Œæ•°æ®")
            return df
        except Exception as e:
            logger.error(f"åŠ è½½æ ‡å‡†æ•°æ®é›†å¤±è´¥: {e}")
            return None
    
    async def generate_reference_answer(self, query: str, contexts: List[str]) -> Dict[str, Any]:
        """
        ä½¿ç”¨LLMç”Ÿæˆæ ‡å‡†ç­”æ¡ˆ
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            contexts: ç›¸å…³ä¸Šä¸‹æ–‡
            
        Returns:
            Dict: ç”Ÿæˆç»“æœ
        """
        try:
            # æ„å»ºæç¤ºè¯
            context_text = "\n\n".join(contexts)
            
            prompt = f"""åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·çš„æŸ¥è¯¢ç”Ÿæˆæ ‡å‡†ç­”æ¡ˆã€‚

ç”¨æˆ·æŸ¥è¯¢: {query}

ä¸Šä¸‹æ–‡ä¿¡æ¯:
{context_text}

è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚ç”Ÿæˆç­”æ¡ˆ:
1. åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ç”¨æˆ·æŸ¥è¯¢
2. ç­”æ¡ˆè¦å‡†ç¡®ã€å®Œæ•´ã€æœ‰é€»è¾‘æ€§
3. å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜
4. ç­”æ¡ˆè¦ç®€æ´æ˜äº†ï¼Œé¿å…å†—ä½™

é‡è¦æ ¼å¼è¦æ±‚:
- ç›´æ¥ç»™å‡ºç­”æ¡ˆå†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•å‰ç¼€
- ä¸è¦ä½¿ç”¨"æ ‡å‡†ç­”æ¡ˆï¼š"ã€"ç­”æ¡ˆï¼š"ã€"å›ç­”ï¼š"ç­‰å‰ç¼€
- ç›´æ¥å¼€å§‹å›ç­”ï¼Œç¬¬ä¸€å¥è¯å°±æ˜¯ç­”æ¡ˆå†…å®¹

è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆ:"""

            # è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
            response = self.openai_client.chat.completions.create(
                model=os.getenv('MODEL_NAME', 'qwen-plus'),
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ï¼Œèƒ½å¤ŸåŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆå‡†ç¡®çš„æ ‡å‡†ç­”æ¡ˆã€‚è¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆå†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•å‰ç¼€å¦‚'æ ‡å‡†ç­”æ¡ˆï¼š'ã€'ç­”æ¡ˆï¼š'ç­‰ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=1000
            )
            
            reference_answer = response.choices[0].message.content.strip()
            
            # æ¸…ç†å¯èƒ½åŒ…å«çš„å‰ç¼€å­—ç¬¦ä¸²
            reference_answer = self.clean_reference_answer(reference_answer)
            
            # æ‰“å°ç”Ÿæˆçš„æ ‡å‡†ç­”æ¡ˆ
            info_print(f"\n{'='*80}")
            info_print(f"ğŸ“ æŸ¥è¯¢: {query}")
            info_print(f"{'='*80}")
            info_print(f"ğŸ¤– ç”Ÿæˆçš„æ ‡å‡†ç­”æ¡ˆ:")
            info_print(f"{reference_answer}")
            info_print(f"{'='*80}\n")
            
            # ä½¿ç”¨ LLM é€‰æ‹©æœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡ä½œä¸ºreference_contexts
            info_print(f"\nğŸ” ä½¿ç”¨ LLM é€‰æ‹©ç›¸å…³ä¸Šä¸‹æ–‡...")
            info_print(f"ğŸ“Š ä¼ å…¥çš„ contexts æ•°é‡: {len(contexts) if contexts else 0}")
            if contexts:
                info_print(f"ğŸ“„ ç¬¬ä¸€ä¸ªåˆ†å—ç¤ºä¾‹: {contexts[0][:100]}...")
            relevant_contexts = await self.select_relevant_contexts_with_llm(query, contexts, max_contexts=10)
            
            # æ‰“å°æ‰€æœ‰æ„å»ºå‡ºçš„åˆ†å—
            info_print(f"\n{'='*80}")
            info_print(f"ğŸ“š reference_contextsæ„å»ºå‡ºçš„æ‰€æœ‰åˆ†å—:")
            info_print(f"{'='*80}")
            info_print(f"ğŸ” æŸ¥è¯¢: {query}")
            info_print(f"ğŸ“Š æ€»ä¸Šä¸‹æ–‡åˆ†å—æ•°: {len(contexts)}")
            info_print(f"ğŸ¯ é€‰æ‹©çš„ç›¸å…³åˆ†å—æ•°: {len(relevant_contexts)}")
            info_print(f"{'='*80}")
            
            for i, chunk in enumerate(relevant_contexts):
                info_print(f"\nğŸ“„ åˆ†å— {i+1}:")
                info_print(f"{'-'*60}")
                info_print(f"{chunk}")
                info_print(f"{'-'*60}")
            
            info_print(f"\n{'='*80}")
            info_print(f"ğŸ“‹ åˆ†å—æ„å»ºå®Œæˆ")
            info_print(f"{'='*80}\n")
            
            # ä½¿ç”¨ Ragas è¯„ä¼°ç”Ÿæˆçš„æ ‡å‡†ç­”æ¡ˆè´¨é‡
            info_print(f"\nğŸ” ä½¿ç”¨ Ragas è¯„ä¼°æ ‡å‡†ç­”æ¡ˆè´¨é‡...")
            ragas_scores = await self.evaluate_with_ragas_metrics(query, reference_answer, relevant_contexts)
            
            return {
                "reference": reference_answer,
                "reference_contexts": relevant_contexts,
                "ragas_scores": ragas_scores
            }
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ ‡å‡†ç­”æ¡ˆå¤±è´¥: {e}")
            return None
    
    def calculate_relevance_score(self, query: str, chunk: str) -> float:
        """
        è®¡ç®—æŸ¥è¯¢ä¸åˆ†å—çš„ç›¸å…³æ€§å¾—åˆ†
        ä½¿ç”¨app.pyä¸­çš„calculate_text_similarityå‡½æ•°
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            chunk: åˆ†å—å†…å®¹
            
        Returns:
            float: ç›¸å…³æ€§å¾—åˆ† (0-1)
        """
        if not query or not chunk:
            return 0.0
        
        # ä½¿ç”¨app.pyä¸­çš„ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°
        similarity = calculate_text_similarity(query, chunk)
        
        return similarity
    
    async def is_chunk_relevant_with_llm(self, query: str, chunk: str) -> bool:
        """
        ä½¿ç”¨ LLM åˆ¤æ–­åˆ†å—æ˜¯å¦ä¸æŸ¥è¯¢ç›¸å…³
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            chunk: æ–‡æ¡£åˆ†å—
            
        Returns:
            bool: æ˜¯å¦ç›¸å…³
        """
        try:
            prompt = f"""
ç”¨æˆ·é—®é¢˜: {query}

æ–‡æ¡£åˆ†å—: {chunk}

# è§’è‰²
è‡ªç„¶è¯­è¨€è¯­ä¹‰ç›¸å…³æ€§åˆ¤å®šä¸“å®¶ï¼Œæ“…é•¿è¿ç”¨å…ˆè¿›çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œç²¾å‡†åˆ¤æ–­æ–‡æœ¬å—ä¸ç»™å®šç”¨æˆ·è¾“å…¥ä¹‹é—´çš„è¯­ä¹‰ç›¸å…³æ€§ã€‚

# ç›®æ ‡
1. åˆ¤å®šå½“å‰åˆ†å—æ˜¯å¦ä¸â€œç”¨æˆ·é—®é¢˜â€è¯­ä¹‰ç›¸å…³ã€‚
2. ç¡®å®šè¯¥åˆ†å—èƒ½å¦ä½œä¸ºå›ç­”â€œç”¨æˆ·é—®é¢˜â€çš„å†…å®¹ç´ æã€‚

# æŠ€èƒ½
1. ç†Ÿç»ƒæŒæ¡è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„è¯­ä¹‰åˆ†ææŠ€æœ¯ã€‚
2. å…·å¤‡æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—çš„èƒ½åŠ›ã€‚

# å·¥ä½œæµç¨‹
1. ä»”ç»†ç†è§£â€œç”¨æˆ·é—®é¢˜â€çš„è¯­ä¹‰ã€æ ¸å¿ƒæ„å›¾ã€å…³é”®è¯ã€‚
2. å¯¹å½“å‰åˆ†å—çš„å†…å®¹è¿›è¡Œæ·±å…¥å‰–æï¼Œæå–å…³é”®ä¿¡æ¯ã€å…³é”®è¯ã€‚
3. è¿ç”¨è¯­ä¹‰åˆ†æå’Œç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•ï¼Œå¯¹æ¯”åˆ†å—ä¸â€œç”¨æˆ·é—®é¢˜â€çš„è¯­ä¹‰ã€å…³é”®è¯ã€‚
4. æ ¹æ®å¯¹æ¯”ç»“æœï¼Œåˆ¤æ–­åˆ†å—æ˜¯å¦ä¸â€œç”¨æˆ·é—®é¢˜â€è¯­ä¹‰ã€å…³é”®è¯è¯­ä¹‰ç›¸å…³ã€‚
5. ç¡®å®šè¯¥åˆ†å—æ˜¯å¦å¯ä½œä¸ºå›ç­”â€œç”¨æˆ·é—®é¢˜â€çš„å†…å®¹ç´ æã€‚

# çº¦æŸ
1. å¿…é¡»ä¸¥æ ¼ä¾æ®è¯­ä¹‰ç›¸å…³æ€§è¿›è¡Œåˆ¤æ–­ï¼Œä¸å¾—å—å…¶ä»–æ— å…³å› ç´ å¹²æ‰°ã€‚
2. ç¦æ­¢ä¸»è§‚è‡†æ–­ï¼Œåˆ¤æ–­ç»“æœéœ€æœ‰åˆç†çš„åˆ†æä¾æ®ã€‚

# è¾“å‡ºæ ¼å¼
åªå›ç­”â€œç›¸å…³â€æˆ–â€œä¸ç›¸å…³â€ï¼Œä¸è¦æ·»åŠ å…¶ä»–å†…å®¹ã€‚
"""
            
            response = await self.llm.ainvoke(prompt)
            result = response.content.strip()
            result_lower = result.lower()
            
            info_print(f"ğŸ¤– LLM å“åº”: {result}")
            
            # åˆ¤æ–­æ˜¯å¦ç›¸å…³
            relevant_keywords = ['ç›¸å…³', 'relevant', 'yes', 'æ˜¯', 'å¯ä»¥', 'èƒ½']
            irrelevant_keywords = ['ä¸ç›¸å…³', 'irrelevant', 'no', 'ä¸æ˜¯', 'ä¸èƒ½', 'ä¸å¯ä»¥']
            
            # ä¼˜å…ˆæ£€æŸ¥ä¸ç›¸å…³çš„å…³é”®è¯
            if any(keyword in result_lower for keyword in irrelevant_keywords):
                info_print(f"âŒ åˆ¤å®šä¸ºä¸ç›¸å…³")
                return False
            
            # ç„¶åæ£€æŸ¥ç›¸å…³çš„å…³é”®è¯
            if any(keyword in result_lower for keyword in relevant_keywords):
                info_print(f"âœ… åˆ¤å®šä¸ºç›¸å…³")
                return True
            
            # å¦‚æœéƒ½æ²¡æœ‰åŒ¹é…åˆ°ï¼Œé»˜è®¤è®¤ä¸ºä¸ç›¸å…³
            info_print(f"âš ï¸ LLM å“åº”ä¸æ˜ç¡®: {result}")
            return False
            
        except Exception as e:
            logger.error(f"LLM åˆ¤æ–­åˆ†å—ç›¸å…³æ€§å¤±è´¥: {e}")
            info_print(f"âš ï¸ LLM è°ƒç”¨å¤±è´¥: {e}")
            # LLM è°ƒç”¨å¤±è´¥æ—¶ï¼Œé»˜è®¤è®¤ä¸ºä¸ç›¸å…³ï¼Œé¿å…é€‰æ‹©é”™è¯¯çš„åˆ†å—
            info_print(f"ğŸ¯ é»˜è®¤åˆ¤æ–­ç»“æœ: ä¸ç›¸å…³")
            return False
    
    async def select_relevant_contexts_with_llm(self, query: str, contexts: List[str], max_contexts: int = 10) -> List[str]:
        """
        ä½¿ç”¨ LLM é€‰æ‹©ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡åˆ†å—
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            contexts: æ‰€æœ‰åˆ†å—åˆ—è¡¨
            max_contexts: æœ€å¤§é€‰æ‹©çš„åˆ†å—æ•°é‡
            
        Returns:
            List[str]: æœ€ç›¸å…³çš„åˆ†å—åˆ—è¡¨
        """
        if not contexts:
            return []
        
        info_print(f"\nğŸ” ä½¿ç”¨ LLM åˆ¤æ–­åˆ†å—ç›¸å…³æ€§...")
        info_print(f"ğŸ“Š æŸ¥è¯¢: {query}")
        info_print(f"ğŸ“š æ€»åˆ†å—æ•°: {len(contexts)}")
        info_print(f"ğŸ¯ æœ€å¤§é€‰æ‹©æ•°: {max_contexts}")
        
        relevant_contexts = []
        
        for i, chunk in enumerate(contexts):
            info_print(f"ğŸ” æ­£åœ¨åˆ¤æ–­åˆ†å— {i+1}/{len(contexts)}...")
            info_print(f"ğŸ“„ åˆ†å—å†…å®¹: {chunk[:100]}...")
            
            # ä½¿ç”¨ LLM åˆ¤æ–­ç›¸å…³æ€§
            is_relevant = await self.is_chunk_relevant_with_llm(query, chunk)
            
            if is_relevant:
                relevant_contexts.append(chunk)
                info_print(f"âœ… åˆ†å— {i+1} è¢«åˆ¤å®šä¸ºç›¸å…³")
                
                # å¦‚æœå·²ç»è¾¾åˆ°æœ€å¤§æ•°é‡ï¼Œåœæ­¢å¤„ç†
                if len(relevant_contexts) >= max_contexts:
                    info_print(f"ğŸ¯ å·²è¾¾åˆ°æœ€å¤§é€‰æ‹©æ•°é‡ {max_contexts}")
                    break
            else:
                info_print(f"âŒ åˆ†å— {i+1} è¢«åˆ¤å®šä¸ºä¸ç›¸å…³")
        
        info_print(f"\nğŸ¯ æœ€ç»ˆé€‰æ‹©äº† {len(relevant_contexts)} ä¸ªç›¸å…³åˆ†å—")
        return relevant_contexts
    
    async def generate_testset_with_ragas(self, knowledge_docs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ Ragas çš„ TestsetGenerator ç”Ÿæˆæµ‹è¯•æ•°æ®é›†
        
        Args:
            knowledge_docs: çŸ¥è¯†åº“æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            List[Dict]: ç”Ÿæˆçš„æµ‹è¯•æ•°æ®
        """
        try:
            # åˆå¹¶æ‰€æœ‰æ–‡æ¡£å†…å®¹
            all_content = []
            for doc in knowledge_docs:
                all_content.extend(doc['chunks'])
            
            # åˆ›å»º TestsetGenerator
            generator = TestsetGenerator.with_openai(
                generator_llm=self.ragas_llm,
                critic_llm=self.ragas_llm
            )
            
            # ç”Ÿæˆæµ‹è¯•é›†
            testset = await generator.agenerate(
                documents=all_content,
                test_size=10,  # ç”Ÿæˆ10ä¸ªæµ‹è¯•æ ·æœ¬
                with_deep_eval=True,
                raise_exceptions=False
            )
            
            logger.info(f"ä½¿ç”¨ Ragas ç”Ÿæˆäº† {len(testset)} ä¸ªæµ‹è¯•æ ·æœ¬")
            return testset
            
        except Exception as e:
            logger.error(f"ä½¿ç”¨ Ragas ç”Ÿæˆæµ‹è¯•é›†å¤±è´¥: {e}")
            return []
    
    async def evaluate_with_ragas_metrics(self, query: str, answer: str, contexts: List[str]) -> Dict[str, float]:
        """
        ç®€åŒ–çš„è¯„ä¼°æ–¹æ³•ï¼Œä¸è¿›è¡Œå¤æ‚çš„è¯„ä¼°è®¡ç®—
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            answer: ç”Ÿæˆçš„æ ‡å‡†ç­”æ¡ˆ
            contexts: ç›¸å…³ä¸Šä¸‹æ–‡
            
        Returns:
            Dict[str, float]: ç©ºçš„è¯„ä¼°æŒ‡æ ‡ï¼ˆä¸è¿›è¡Œè¯„ä¼°ï¼‰
        """
        info_print(f"\nğŸ” è·³è¿‡å¤æ‚è¯„ä¼°ï¼Œç›´æ¥è¿”å›ç©ºç»“æœ...")
        return {}

    def clean_reference_answer(self, answer: str) -> str:
        """
        æ¸…ç†æ ‡å‡†ç­”æ¡ˆä¸­çš„å‰ç¼€å­—ç¬¦ä¸²
        
        Args:
            answer: åŸå§‹ç­”æ¡ˆ
            
        Returns:
            str: æ¸…ç†åçš„ç­”æ¡ˆ
        """
        if not answer:
            return answer
        
        # éœ€è¦æ¸…ç†çš„å‰ç¼€å­—ç¬¦ä¸²åˆ—è¡¨
        prefixes_to_remove = [
            "æ ‡å‡†ç­”æ¡ˆï¼š",
            "æ ‡å‡†ç­”æ¡ˆ:",
            "ç­”æ¡ˆï¼š",
            "ç­”æ¡ˆ:",
            "å›ç­”ï¼š",
            "å›ç­”:",
            "Reference Answer:",
            "Reference Answerï¼š",
            "Answer:",
            "Answerï¼š"
        ]
        
        # æ¸…ç†å‰ç¼€
        cleaned_answer = answer.strip()
        for prefix in prefixes_to_remove:
            if cleaned_answer.startswith(prefix):
                cleaned_answer = cleaned_answer[len(prefix):].strip()
                break
        
        return cleaned_answer
    
    
    
    
    
    def format_contexts(self, contexts: List[str]) -> str:
        """
        æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ï¼Œåˆ†å—ä¹‹é—´ç”¨ç©ºè¡Œåˆ†éš”
        
        Args:
            contexts: ä¸Šä¸‹æ–‡åˆ—è¡¨
            
        Returns:
            str: æ ¼å¼åŒ–åçš„ä¸Šä¸‹æ–‡
        """
        info_print(f"ğŸ”§ format_contexts è°ƒè¯•:")
        info_print(f"  è¾“å…¥ contexts ç±»å‹: {type(contexts)}")
        info_print(f"  è¾“å…¥ contexts é•¿åº¦: {len(contexts) if contexts else 0}")
        
        if not contexts:
            info_print(f"  âš ï¸ contexts ä¸ºç©ºï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²")
            return ""
        
        # è¿‡æ»¤æ‰ç©ºçš„åˆ†å—
        filtered_contexts = [ctx for ctx in contexts if ctx.strip()]
        info_print(f"  è¿‡æ»¤ååˆ†å—æ•°é‡: {len(filtered_contexts)}")
        
        if filtered_contexts:
            info_print(f"  ç¬¬ä¸€ä¸ªåˆ†å—ç¤ºä¾‹: {filtered_contexts[0][:50]}...")
        
        # ä½¿ç”¨ç©ºè¡Œè¿æ¥åˆ†å—
        result = "\n\n".join(filtered_contexts)
        info_print(f"  æ ¼å¼åŒ–ç»“æœé•¿åº¦: {len(result)}")
        return result
    
    async def build_reference_data(self, df: pd.DataFrame, 
                                 knowledge_docs: List[Dict[str, Any]]) -> pd.DataFrame:
        """
        æ„å»ºæ ‡å‡†ç­”æ¡ˆæ•°æ®
        
        Args:
            df: æ ‡å‡†æ•°æ®é›†DataFrame
            knowledge_docs: çŸ¥è¯†åº“æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            pd.DataFrame: æ›´æ–°åçš„DataFrame
        """
        # åˆå¹¶æ‰€æœ‰çŸ¥è¯†åº“æ–‡æ¡£çš„åˆ†å—
        all_chunks = []
        for doc in knowledge_docs:
            all_chunks.extend(doc['chunks'])
        
        logger.info(f"æ€»å…±æœ‰ {len(all_chunks)} ä¸ªçŸ¥è¯†åº“åˆ†å—")
        info_print(f"ğŸ“Š çŸ¥è¯†åº“åˆ†å—ç»Ÿè®¡:")
        info_print(f"  ğŸ“š æ–‡æ¡£æ•°é‡: {len(knowledge_docs)}")
        info_print(f"  ğŸ“„ æ€»åˆ†å—æ•°: {len(all_chunks)}")
        if all_chunks:
            info_print(f"  ğŸ“ ç¬¬ä¸€ä¸ªåˆ†å—ç¤ºä¾‹: {all_chunks[0][:100]}...")
        else:
            info_print(f"  âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åˆ†å—ï¼")
        
        for index, row in df.iterrows():
            try:
                query = row['user_input']
                logger.info(f"å¤„ç†æŸ¥è¯¢ {index + 1}/{len(df)}: {query[:50]}...")
                
                # ç”Ÿæˆæ ‡å‡†ç­”æ¡ˆ
                result = await self.generate_reference_answer(query, all_chunks)
                
                if result:
                    # æ›´æ–°reference_contextså’Œreference
                    reference_contexts = result.get('reference_contexts', [])
                    info_print(f"ğŸ”§ å‡†å¤‡ä¿å­˜ reference_contexts:")
                    info_print(f"  reference_contexts ç±»å‹: {type(reference_contexts)}")
                    info_print(f"  reference_contexts é•¿åº¦: {len(reference_contexts) if reference_contexts else 0}")
                    
                    formatted_contexts = self.format_contexts(reference_contexts)
                    df.at[index, 'reference_contexts'] = str(formatted_contexts)
                    df.at[index, 'reference'] = str(result.get('reference', ''))
                    
                    info_print(f"ğŸ’¾ ä¿å­˜åˆ° DataFrame:")
                    info_print(f"  reference_contexts åˆ—å€¼é•¿åº¦: {len(str(formatted_contexts))}")
                    info_print(f"  reference åˆ—å€¼é•¿åº¦: {len(str(result.get('reference', '')))}")
                    
                    logger.info(f"âœ… æˆåŠŸç”Ÿæˆæ ‡å‡†ç­”æ¡ˆ: {index + 1}/{len(df)}")
                    info_print(f"âœ… ç¬¬ {index + 1}/{len(df)} æ¡æ ‡å‡†ç­”æ¡ˆç”Ÿæˆå®Œæˆ")
                else:
                    logger.warning(f"âŒ ç”Ÿæˆæ ‡å‡†ç­”æ¡ˆå¤±è´¥: {index + 1}")
                    info_print(f"âŒ ç¬¬ {index + 1}/{len(df)} æ¡æ ‡å‡†ç­”æ¡ˆç”Ÿæˆå¤±è´¥")
                    
            except Exception as e:
                logger.error(f"å¤„ç†æŸ¥è¯¢å¤±è´¥ {index + 1}: {e}")
                continue
        
        return df
    
    def save_updated_dataset(self, df: pd.DataFrame) -> bool:
        """
        ä¿å­˜æ›´æ–°åçš„æ•°æ®é›†
        
        Args:
            df: æ›´æ–°åçš„DataFrame
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            self.standard_dataset_path.parent.mkdir(parents=True, exist_ok=True)
            
            # ç¡®ä¿reference_contextså’Œreferenceåˆ—çš„æ•°æ®ç±»å‹ä¸ºå­—ç¬¦ä¸²
            if 'reference_contexts' in df.columns:
                df['reference_contexts'] = df['reference_contexts'].astype(str)
            if 'reference' in df.columns:
                df['reference'] = df['reference'].astype(str)
            
            # å¦‚æœåŸæ–‡ä»¶è¢«å ç”¨ï¼Œä½¿ç”¨å¤‡ä»½æ–‡ä»¶å
            save_path = self.standard_dataset_path
            if save_path.exists():
                backup_path = save_path.parent / f"{save_path.stem}_updated{save_path.suffix}"
                save_path = backup_path
            
            # ä¿å­˜æ–‡ä»¶
            df.to_excel(save_path, index=False)
            
            # ä½¿ç”¨ openpyxl è°ƒæ•´è¡Œé«˜å’Œåˆ—å®½
            self._adjust_excel_formatting(save_path)
            
            logger.info(f"æ•°æ®é›†ä¿å­˜æˆåŠŸ: {save_path}")
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ•°æ®é›†å¤±è´¥: {e}")
            return False
    
    def _adjust_excel_formatting(self, file_path: Path) -> None:
        """
        è°ƒæ•´ Excel æ–‡ä»¶çš„æ ¼å¼ï¼Œè®©å•å…ƒæ ¼è·Ÿéšå†…å®¹è‡ªé€‚åº”æ˜¾ç¤º
        
        Args:
            file_path: Excel æ–‡ä»¶è·¯å¾„
        """
        try:
            # åŠ è½½å·¥ä½œç°¿
            workbook = load_workbook(file_path)
            worksheet = workbook.active
            
            # 1. è®¾ç½®å•å…ƒæ ¼æ ¼å¼ï¼ˆè‡ªåŠ¨æ¢è¡Œå’Œå¯¹é½ï¼‰
            for row in worksheet.iter_rows():
                for cell in row:
                    cell.alignment = Alignment(
                        wrap_text=True,      # è‡ªåŠ¨æ¢è¡Œ
                        vertical='top',      # å‚ç›´é¡¶éƒ¨å¯¹é½
                        horizontal='left'    # æ°´å¹³å·¦å¯¹é½
                    )
            
            # 2. è‡ªé€‚åº”åˆ—å®½
            for col in worksheet.columns:
                # è·å–åˆ—ç´¢å¼•ï¼ˆä»1å¼€å§‹ï¼‰
                col_idx = col[0].column
                # è®¡ç®—è¯¥åˆ—ä¸­æœ€é•¿å†…å®¹çš„é•¿åº¦
                max_length = max(len(str(cell.value)) for cell in col if cell.value)
                # è®¾ç½®åˆ—å®½ï¼ˆåŠ 2æ˜¯ä¸ºäº†ç•™ä¸€äº›ä½™é‡ï¼Œé™åˆ¶æœ€å¤§å®½åº¦ä¸º50ï¼‰
                adjusted_width = min(max_length + 2, 50)
                worksheet.column_dimensions[get_column_letter(col_idx)].width = adjusted_width
            
            # 3. è‡ªé€‚åº”è¡Œé«˜
            for row_idx, row in enumerate(worksheet.iter_rows(), 1):
                max_height = 15  # é»˜è®¤è¡Œé«˜
                
                for cell in row:
                    if cell.value:
                        text = str(cell.value)
                        # è®¡ç®—æ–‡æœ¬è¡Œæ•°ï¼ˆåŸºäºæ¢è¡Œç¬¦ï¼‰
                        lines = text.count('\n') + 1
                        
                        # æ ¹æ®åˆ—å®½ä¼°ç®—å¯èƒ½çš„æ¢è¡Œæ•°
                        col_letter = get_column_letter(cell.column)
                        col_width = worksheet.column_dimensions[col_letter].width
                        if col_width > 0:
                            # ä¼°ç®—æ¯è¡Œèƒ½å®¹çº³çš„å­—ç¬¦æ•°ï¼ˆä¸­æ–‡å­—ç¬¦æŒ‰2ä¸ªå­—ç¬¦è®¡ç®—ï¼‰
                            chars_per_line = int(col_width * 1.5)
                            estimated_lines = len(text) // chars_per_line + 1
                            lines = max(lines, estimated_lines)
                        
                        # æ¯è¡Œå¤§çº¦15åƒç´ é«˜åº¦
                        cell_height = lines * 15
                        max_height = max(max_height, cell_height)
                
                # è®¾ç½®è¡Œé«˜ï¼ˆé™åˆ¶æœ€å¤§é«˜åº¦ä¸º200ï¼‰
                adjusted_height = min(max(max_height, 15), 200)
                worksheet.row_dimensions[row_idx].height = adjusted_height
            
            # ä¿å­˜æ–‡ä»¶
            workbook.save(file_path)
            logger.info(f"Excel æ ¼å¼è°ƒæ•´å®Œæˆï¼Œå•å…ƒæ ¼å·²è‡ªé€‚åº”å†…å®¹: {file_path}")
            
        except Exception as e:
            logger.error(f"è°ƒæ•´ Excel æ ¼å¼å¤±è´¥: {e}")
    
    async def build_dataset(self) -> Dict[str, Any]:
        """
        æ„å»ºæ ‡å‡†æ•°æ®é›†çš„ä¸»å‡½æ•°
        
        Returns:
            Dict: æ„å»ºç»“æœ
        """
        try:
            logger.info("å¼€å§‹æ„å»ºæ ‡å‡†æ•°æ®é›†...")
            
            # 1. åŠ è½½çŸ¥è¯†åº“æ–‡æ¡£
            knowledge_docs = self.load_knowledge_documents()
            if not knowledge_docs:
                return {
                    "success": False,
                    "message": "æ²¡æœ‰æ‰¾åˆ°çŸ¥è¯†åº“æ–‡æ¡£"
                }
            
            # 2. åŠ è½½æ ‡å‡†æ•°æ®é›†
            df = self.load_standard_dataset()
            if df is None:
                return {
                    "success": False,
                    "message": "åŠ è½½æ ‡å‡†æ•°æ®é›†å¤±è´¥"
                }
            
            # 3. æ„å»ºæ ‡å‡†ç­”æ¡ˆæ•°æ®
            updated_df = await self.build_reference_data(df, knowledge_docs)
            
            # 4. ä¿å­˜æ›´æ–°åçš„æ•°æ®é›†
            if self.save_updated_dataset(updated_df):
                # æ‰“å°æ‰€æœ‰ç”Ÿæˆçš„æ ‡å‡†ç­”æ¡ˆæ‘˜è¦
                info_print(f"\n{'='*100}")
                info_print(f"ğŸ“Š æ ‡å‡†æ•°æ®é›†æ„å»ºå®Œæˆæ‘˜è¦")
                info_print(f"{'='*100}")
                info_print(f"ğŸ“ˆ æ€»å¤„ç†æŸ¥è¯¢æ•°: {len(df)}")
                info_print(f"ğŸ“š çŸ¥è¯†åº“æ–‡æ¡£æ•°: {len(knowledge_docs)}")
                info_print(f"ğŸ’¾ ä¿å­˜è·¯å¾„: {self.standard_dataset_path}")
                info_print(f"{'='*100}")
                
                # æ‰“å°æ‰€æœ‰ç”Ÿæˆçš„æ ‡å‡†ç­”æ¡ˆ
                info_print(f"\nğŸ“‹ æ‰€æœ‰ç”Ÿæˆçš„æ ‡å‡†ç­”æ¡ˆ:")
                info_print(f"{'='*100}")
                for index, row in updated_df.iterrows():
                    if pd.notna(row.get('reference', '')):
                        info_print(f"\nğŸ”¸ æŸ¥è¯¢ {index + 1}: {row['user_input'][:50]}...")
                        
                        # æ‰“å°æ‰€æœ‰reference_contextsçš„åˆ†å—
                        reference_contexts = row.get('reference_contexts', '')
                        if reference_contexts and reference_contexts != 'nan':
                            info_print(f"\nğŸ“š reference_contexts åˆ†å—å†…å®¹:")
                            info_print(f"{'='*80}")
                            
                            # å°†reference_contextsæŒ‰åˆ†å—åˆ†å‰²ï¼ˆå‡è®¾ç”¨åŒæ¢è¡Œç¬¦åˆ†éš”ï¼‰
                            if isinstance(reference_contexts, str):
                                chunks = reference_contexts.split('\n\n')
                                for i, chunk in enumerate(chunks):
                                    if chunk.strip():  # åªæ˜¾ç¤ºéç©ºåˆ†å—
                                        info_print(f"\nğŸ“„ åˆ†å— {i+1}:")
                                        info_print(f"{'-'*60}")
                                        info_print(f"{chunk.strip()}")
                                        info_print(f"{'-'*60}")
                            else:
                                info_print(f"reference_contexts ä¸æ˜¯å­—ç¬¦ä¸²æ ¼å¼: {type(reference_contexts)}")
                        else:
                            info_print(f"\nâš ï¸  reference_contexts ä¸ºç©ºæˆ–æ— æ•ˆ")
                        
                        info_print(f"\nğŸ“ æ ‡å‡†ç­”æ¡ˆ: {row['reference']}")
                        info_print(f"{'-'*80}")
                
                return {
                    "success": True,
                    "message": f"æ•°æ®é›†æ„å»ºæˆåŠŸï¼å¤„ç†äº† {len(df)} æ¡æŸ¥è¯¢",
                    "processed_count": len(df),
                    "knowledge_docs_count": len(knowledge_docs)
                }
            else:
                return {
                    "success": False,
                    "message": "ä¿å­˜æ•°æ®é›†å¤±è´¥"
                }
                
        except Exception as e:
            logger.error(f"æ„å»ºæ•°æ®é›†å¼‚å¸¸: {e}")
            return {
                "success": False,
                "message": f"æ„å»ºæ•°æ®é›†å¤±è´¥: {str(e)}"
            }

# ä¾¿æ·å‡½æ•°
async def build_standard_dataset() -> Dict[str, Any]:
    """
    æ„å»ºæ ‡å‡†æ•°æ®é›†çš„ä¾¿æ·å‡½æ•°
    
    Returns:
        Dict: æ„å»ºç»“æœ
    """
    builder = StandardDatasetBuilder()
    return await builder.build_dataset()

# æµ‹è¯•å‡½æ•°
async def test_build_dataset():
    """æµ‹è¯•æ„å»ºæ•°æ®é›†åŠŸèƒ½"""
    info_print("ğŸ” æµ‹è¯•æ ‡å‡†æ•°æ®é›†æ„å»ºåŠŸèƒ½...")
    
    result = await build_standard_dataset()
    info_print(f"ğŸ“‹ æ„å»ºç»“æœ: {result}")
    
    if result["success"]:
        info_print("âœ… æ•°æ®é›†æ„å»ºæˆåŠŸ")
    else:
        info_print("âŒ æ•°æ®é›†æ„å»ºå¤±è´¥")

if __name__ == "__main__":
    asyncio.run(test_build_dataset())
