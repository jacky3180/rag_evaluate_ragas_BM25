"""
RAGè¯„ä¼°æŒ‡æ ‡MAP (Mean Average Precision) å®ç°
ç”¨äºè®¡ç®—æ£€ç´¢ç³»ç»Ÿä¸­ç›¸å…³åˆ†å—çš„å¹³å‡ç²¾åº¦

åŠŸèƒ½ï¼š
1. åŠ è½½RAGæ ·æœ¬æ•°æ®å’Œåˆ†å—æ•°æ®
2. ä½¿ç”¨BM25ç®—æ³•åˆ¤æ–­åˆ†å—ç›¸å…³æ€§
3. è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„å¹³å‡ç²¾åº¦(AP)
4. è®¡ç®—MAPæŒ‡æ ‡
5. æŒ‰æ ·æœ¬åˆ†ç»„æ˜¾ç¤ºè®¡ç®—è¿‡ç¨‹
"""

import os
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
from config import debug_print, verbose_print, info_print, error_print, QUIET_MODE
from read_chuck import EvaluationConfig, DataLoader, TextProcessor
from BM25_evaluate import BM25Evaluator, BM25, find_relevant_chunks, is_chunk_relevant


class MAPEvaluator:
    """MAP (Mean Average Precision) è¯„ä¼°å™¨"""
    
    def __init__(self, config: EvaluationConfig):
        """
        åˆå§‹åŒ–MAPè¯„ä¼°å™¨
        
        Args:
            config: è¯„ä¼°é…ç½®
        """
        self.config = config
        self.data_loader = DataLoader(config)
        self.text_processor = TextProcessor(config)
        self.bm25_evaluator = BM25Evaluator(config)
        
        # ç›¸å…³æ€§é˜ˆå€¼
        self.relevance_threshold = float(os.getenv("SIMILARITY_THRESHOLD", "0.5"))
        
        info_print("ğŸ”§ MAPè¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ")
        info_print(f"ğŸ“Š ç›¸å…³æ€§é˜ˆå€¼: {self.relevance_threshold}")
    
    def load_and_process_data(self) -> Optional[pd.DataFrame]:
        """
        åŠ è½½å’Œå¤„ç†RAGæ ·æœ¬æ•°æ®
        
        Returns:
            pd.DataFrame: å¤„ç†åçš„æ•°æ®ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        info_print("ğŸ“– åŠ è½½RAGæ ·æœ¬æ•°æ®...")
        
        # ä½¿ç”¨BM25Evaluatorçš„æ•°æ®åŠ è½½åŠŸèƒ½
        df = self.bm25_evaluator.load_and_process_data()
        if df is None:
            error_print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            return None
        
        info_print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} ä¸ªRAGæ ·æœ¬")
        return df
    
    def get_relevant_chunks_for_query(self, query: str, reference_contexts: List[str]) -> List[str]:
        """
        è·å–ä¸æŸ¥è¯¢ç›¸å…³çš„å‚è€ƒåˆ†å—
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            reference_contexts: å‚è€ƒåˆ†å—åˆ—è¡¨
            
        Returns:
            List[str]: ç›¸å…³åˆ†å—åˆ—è¡¨
        """
        if not query or not reference_contexts:
            return []
        
        relevant_chunks = []
        for chunk in reference_contexts:
            # ä½¿ç”¨BM25ç®—æ³•åˆ¤æ–­ç›¸å…³æ€§
            is_relevant, score = is_chunk_relevant(query, chunk, threshold=-10.0)  # ä½¿ç”¨è¾ƒä½çš„BM25é˜ˆå€¼
            if is_relevant:
                relevant_chunks.append(chunk)
        
        return relevant_chunks
    
    def get_ranked_chunks_for_query(self, query: str, retrieved_contexts: List[str]) -> List[Tuple[str, float]]:
        """
        è·å–æŒ‰ç›¸å…³æ€§æ’åºçš„æ£€ç´¢åˆ†å—
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            retrieved_contexts: æ£€ç´¢åˆ†å—åˆ—è¡¨
            
        Returns:
            List[Tuple[str, float]]: æ’åºåçš„åˆ†å—åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(åˆ†å—å†…å®¹, ç›¸å…³æ€§åˆ†æ•°)
        """
        if not query or not retrieved_contexts:
            return []
        
        # ä½¿ç”¨BM25ç®—æ³•å¯¹æ£€ç´¢åˆ†å—è¿›è¡Œæ’åº
        ranked_chunks = find_relevant_chunks(
            query=query,
            chunks=retrieved_contexts,
            max_chunks=len(retrieved_contexts),
            threshold=-10.0  # ä½¿ç”¨è¾ƒä½çš„é˜ˆå€¼ä»¥åŒ…å«æ‰€æœ‰åˆ†å—
        )
        
        return ranked_chunks
    
    def calculate_average_precision(self, query: str, retrieved_contexts: List[str], 
                                  reference_contexts: List[str]) -> Tuple[float, Dict[str, Any]]:
        """
        è®¡ç®—å•ä¸ªæŸ¥è¯¢çš„å¹³å‡ç²¾åº¦(AP)
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            retrieved_contexts: æ£€ç´¢åˆ†å—åˆ—è¡¨
            reference_contexts: å‚è€ƒåˆ†å—åˆ—è¡¨
            
        Returns:
            Tuple[float, Dict[str, Any]]: (å¹³å‡ç²¾åº¦, è¯¦ç»†è®¡ç®—è¿‡ç¨‹)
        """
        # è·å–ç›¸å…³åˆ†å—
        relevant_chunks = self.get_relevant_chunks_for_query(query, reference_contexts)
        
        if not relevant_chunks:
            # å¦‚æœæ²¡æœ‰ç›¸å…³åˆ†å—ï¼Œè¿”å›0
            debug_print(f"  æŸ¥è¯¢: {query[:50]}... - æ— ç›¸å…³åˆ†å—")
            return 0.0, {
                'relevant_chunks': [],
                'precision_at_k': [],
                'relevant_positions': [],
                'calculation_steps': [],
                'chunk_relevance_scores': [],
                'total_relevant': 0,
                'total_retrieved': len(retrieved_contexts) if retrieved_contexts else 0
            }
        
        if not retrieved_contexts:
            # å¦‚æœæ²¡æœ‰æ£€ç´¢åˆ†å—ï¼Œè¿”å›0
            debug_print(f"  æŸ¥è¯¢: {query[:50]}... - æ— æ£€ç´¢åˆ†å—")
            return 0.0, {
                'relevant_chunks': relevant_chunks,
                'precision_at_k': [],
                'relevant_positions': [],
                'calculation_steps': [],
                'chunk_relevance_scores': [],
                'total_relevant': 0,
                'total_retrieved': 0
            }
        
        # è®¡ç®—æ¯ä¸ªæ£€ç´¢åˆ†å—ä¸ç›¸å…³åˆ†å—çš„ç›¸å…³æ€§
        chunk_relevance_scores = []
        for i, retrieved_chunk in enumerate(retrieved_contexts):
            max_relevance = 0.0
            best_ref_chunk = ""
            for ref_chunk in relevant_chunks:
                relevance = self.bm25_evaluator.calculate_relevance_score(retrieved_chunk, ref_chunk)
                if relevance > max_relevance:
                    max_relevance = relevance
                    best_ref_chunk = ref_chunk
            
            # ä½ç½® = æ€»é•¿åº¦ - åŸå§‹indexï¼ˆå€’åºï¼‰
            position = len(retrieved_contexts) - i
            
            chunk_relevance_scores.append({
                'position': position,
                'chunk': retrieved_chunk,
                'relevance_score': max_relevance,
                'is_relevant': max_relevance > self.relevance_threshold,
                'best_ref_chunk': best_ref_chunk
            })
        
        # è®¡ç®—å¹³å‡ç²¾åº¦
        relevant_count = 0
        precision_sum = 0.0
        precision_at_k = []
        relevant_positions = []
        calculation_steps = []
        
        for i, chunk_info in enumerate(chunk_relevance_scores):
            if chunk_info['is_relevant']:
                relevant_count += 1
                # ä½¿ç”¨å€’åºä½ç½®è®¡ç®—ç²¾åº¦
                position = chunk_info['position']
                precision_at_i = relevant_count / position
                precision_sum += precision_at_i
                precision_at_k.append(precision_at_i)
                relevant_positions.append(position)
                
                calculation_steps.append({
                    'position': position,
                    'precision': precision_at_i,
                    'relevant_count': relevant_count,
                    'total_retrieved': position
                })
        
        # è®¡ç®—å¹³å‡ç²¾åº¦
        if relevant_count > 0:
            average_precision = precision_sum / relevant_count
        else:
            average_precision = 0.0
        
        return average_precision, {
            'relevant_chunks': relevant_chunks,
            'precision_at_k': precision_at_k,
            'relevant_positions': relevant_positions,
            'calculation_steps': calculation_steps,
            'chunk_relevance_scores': chunk_relevance_scores,
            'total_relevant': relevant_count,
            'total_retrieved': len(retrieved_contexts)
        }
    
    def evaluate_map(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        è®¡ç®—MAPæŒ‡æ ‡
        
        Args:
            df: å¤„ç†åçš„æ•°æ®
            
        Returns:
            Dict[str, Any]: MAPè¯„ä¼°ç»“æœ
        """
        info_print("ğŸ” å¼€å§‹MAPè¯„ä¼°...")
        info_print("ğŸ“‹ è¯„ä¼°é€»è¾‘:")
        info_print("  â€¢ MAP = æ‰€æœ‰æŸ¥è¯¢çš„å¹³å‡ç²¾åº¦(AP)çš„å¹³å‡å€¼")
        info_print("  â€¢ AP = æ¯ä¸ªç›¸å…³åˆ†å—è¢«æ£€ç´¢åˆ°æ—¶çš„ç²¾åº¦å€¼çš„å¹³å‡å€¼")
        info_print("  â€¢ ç²¾åº¦@k = å‰kä¸ªæ£€ç´¢ç»“æœä¸­ç›¸å…³åˆ†å—çš„æ•°é‡ / k")
        info_print(f"  â€¢ ç›¸å…³æ€§åˆ¤æ–­: æ£€ç´¢åˆ†å—ä¸å‚è€ƒåˆ†å—çš„è¯­ä¹‰ç›¸ä¼¼åº¦ > {self.relevance_threshold}")
        info_print()
        
        results = {
            'average_precisions': [],
            'detailed_results': [],
            'total_queries': 0,
            'queries_with_relevant_chunks': 0,
            'queries_without_relevant_chunks': 0
        }
        
        # è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„MAP
        for idx, row in df.iterrows():
            # å®‰å…¨è·å–å­—ç¬¦ä¸²å€¼
            user_input_val = row.get('user_input', '')
            user_input = str(user_input_val) if user_input_val is not None and not pd.isna(user_input_val) else ""
            
            # ç¡®ä¿ç±»å‹è½¬æ¢ï¼šä»pandas Seriesè½¬æ¢ä¸ºList[str]
            retrieved_contexts_raw = row['retrieved_contexts']
            reference_contexts_raw = row['reference_contexts']
            
            retrieved_contexts = retrieved_contexts_raw if isinstance(retrieved_contexts_raw, list) else list(retrieved_contexts_raw) if retrieved_contexts_raw is not None else []
            reference_contexts = reference_contexts_raw if isinstance(reference_contexts_raw, list) else list(reference_contexts_raw) if reference_contexts_raw is not None else []
            
            # å®‰å…¨æ£€æŸ¥ï¼šå¤„ç†ç©ºå€¼å’ŒNaN
            if not retrieved_contexts or not reference_contexts or len(retrieved_contexts) == 0 or len(reference_contexts) == 0:
                # å¯¹äºç©ºæ£€ç´¢ç»“æœï¼Œå¹³å‡ç²¾åº¦ä¸º0
                results['average_precisions'].append(0.0)
                results['total_queries'] += 1
                results['queries_without_relevant_chunks'] += 1
                results['detailed_results'].append({
                    'row_index': idx,
                    'user_input': user_input,
                    'average_precision': 0.0,
                    'retrieved_count': len(retrieved_contexts) if retrieved_contexts else 0,
                    'reference_count': len(reference_contexts) if reference_contexts else 0,
                    'relevant_chunks_count': 0,
                    'calculation_details': {
                        'relevant_chunks': [],
                        'precision_at_k': [],
                        'relevant_positions': [],
                        'calculation_steps': [],
                        'chunk_relevance_scores': [],
                        'total_relevant': 0,
                        'total_retrieved': len(retrieved_contexts) if retrieved_contexts else 0
                    }
                })
                continue
            
            # ç¡®ä¿ç±»å‹è½¬æ¢ï¼šä»pandas Seriesè½¬æ¢ä¸ºList[str]
            retrieved_contexts_list = retrieved_contexts if isinstance(retrieved_contexts, list) else list(retrieved_contexts) if retrieved_contexts is not None else []
            reference_contexts_list = reference_contexts if isinstance(reference_contexts, list) else list(reference_contexts) if reference_contexts is not None else []
            
            # è®¡ç®—å¹³å‡ç²¾åº¦
            average_precision, calculation_details = self.calculate_average_precision(
                user_input, retrieved_contexts_list, reference_contexts_list
            )
            
            results['average_precisions'].append(average_precision)
            results['total_queries'] += 1
            
            if average_precision > 0:
                results['queries_with_relevant_chunks'] += 1
            else:
                results['queries_without_relevant_chunks'] += 1
            
            # è¯¦ç»†ç»“æœ
            results['detailed_results'].append({
                'row_index': idx,
                'user_input': user_input,
                'average_precision': average_precision,
                'retrieved_count': len(retrieved_contexts),
                'reference_count': len(reference_contexts),
                'relevant_chunks_count': len(self.get_relevant_chunks_for_query(user_input, reference_contexts)),
                'calculation_details': calculation_details
            })
        
        # æŒ‰æ ·æœ¬åˆ†ç»„æ˜¾ç¤ºç»“æœ
        info_print("\n" + "=" * 80)
        info_print("ğŸ“Š æ ·æœ¬MAPè¯„ä¼°ç»“æœ")
        info_print("=" * 80)
        
        for result in results['detailed_results']:
            sample_idx = result['row_index'] + 1
            user_input = result['user_input']
            average_precision = result['average_precision']
            retrieved_count = result['retrieved_count']
            reference_count = result['reference_count']
            relevant_count = result['relevant_chunks_count']
            details = result['calculation_details']
            
            info_print(f"\nğŸ“‹ æ ·æœ¬ {sample_idx}:")
            info_print(f"  æŸ¥è¯¢: {user_input}")
            info_print(f"  æ£€ç´¢åˆ†å—æ•°: {retrieved_count}ä¸ª, å‚è€ƒåˆ†å—æ•°: {reference_count}ä¸ª")
            info_print(f"  ç›¸å…³åˆ†å—æ•°: {relevant_count}ä¸ª")
            
            if average_precision > 0:
                info_print(f"  ğŸ“Š APå¾—åˆ†: {average_precision:.4f}")
                
                # æ˜¾ç¤ºè®¡ç®—è¿‡ç¨‹
                if details['calculation_steps']:
                    info_print(f"  ğŸ“ˆ è®¡ç®—è¿‡ç¨‹:")
                    for step in details['calculation_steps']:
                        info_print(f"    ä½ç½®{step['position']}: ç²¾åº¦@{step['total_retrieved']} = {step['precision']:.4f} "
                                 f"(ç›¸å…³åˆ†å—æ•°: {step['relevant_count']}/{step['total_retrieved']})")
                
                # æ˜¾ç¤ºç›¸å…³åˆ†å—ä½ç½®
                if details['relevant_positions']:
                    info_print(f"  ğŸ¯ ç›¸å…³åˆ†å—ä½ç½®: {details['relevant_positions']}")
                    info_print(f"  ğŸ“Š ç²¾åº¦@kåºåˆ—: {[f'{p:.4f}' for p in details['precision_at_k']]}")
            else:
                info_print(f"  âŒ æ— ç›¸å…³åˆ†å—")
                info_print(f"  ğŸ“Š APå¾—åˆ†: 0.0000")
        
        # è®¡ç®—MAP
        if results['average_precisions']:
            results['map'] = np.mean(results['average_precisions'])
        else:
            results['map'] = 0.0
        
        info_print(f"\nâœ… MAPè¯„ä¼°å®Œæˆ")
        info_print(f"ğŸ“Š MAP: {results['map']:.4f}")
        info_print(f"ğŸ“Š æ€»æŸ¥è¯¢æ•°: {results['total_queries']}")
        info_print(f"ğŸ“Š æœ‰ç›¸å…³åˆ†å—çš„æŸ¥è¯¢æ•°: {results['queries_with_relevant_chunks']}")
        info_print(f"ğŸ“Š æ— ç›¸å…³åˆ†å—çš„æŸ¥è¯¢æ•°: {results['queries_without_relevant_chunks']}")
        
        return results
    
    def print_detailed_analysis(self, results: Dict[str, Any]):
        """
        æ‰“å°è¯¦ç»†çš„MAPåˆ†æç»“æœ
        
        Args:
            results: MAPè¯„ä¼°ç»“æœ
        """
        info_print("\n" + "=" * 80)
        info_print("ğŸ“Š MAPè¯¦ç»†åˆ†æ")
        info_print("=" * 80)
        
        info_print("ğŸ“‹ MAPæŒ‡æ ‡è¯´æ˜:")
        info_print("  â€¢ MAP (Mean Average Precision) = å¹³å‡å¹³å‡ç²¾åº¦")
        info_print("  â€¢ AP (Average Precision) = æ¯ä¸ªç›¸å…³åˆ†å—è¢«æ£€ç´¢åˆ°æ—¶çš„ç²¾åº¦å€¼çš„å¹³å‡å€¼")
        info_print("  â€¢ ç²¾åº¦@k = å‰kä¸ªæ£€ç´¢ç»“æœä¸­ç›¸å…³åˆ†å—çš„æ•°é‡ / k")
        info_print("  â€¢ å¦‚æœæ²¡æœ‰ç›¸å…³åˆ†å—ï¼ŒAPä¸º0")
        info_print(f"  â€¢ ç›¸å…³æ€§é˜ˆå€¼: {self.relevance_threshold}")
        info_print()
        
        info_print("ğŸ“Š è¯„ä¼°ç»“æœ:")
        info_print(f"1. MAP: {results['map']:.4f} ({results['map']*100:.1f}%)")
        info_print(f"2. æ€»æŸ¥è¯¢æ•°: {results['total_queries']}")
        info_print(f"3. æœ‰ç›¸å…³åˆ†å—çš„æŸ¥è¯¢æ•°: {results['queries_with_relevant_chunks']}")
        info_print(f"4. æ— ç›¸å…³åˆ†å—çš„æŸ¥è¯¢æ•°: {results['queries_without_relevant_chunks']}")
        
        if results['total_queries'] > 0:
            coverage = results['queries_with_relevant_chunks'] / results['total_queries']
            info_print(f"5. ç›¸å…³åˆ†å—è¦†ç›–ç‡: {coverage:.4f} ({coverage*100:.1f}%)")
        
        # å¹³å‡ç²¾åº¦åˆ†å¸ƒç»Ÿè®¡
        average_precisions = results['average_precisions']
        if average_precisions:
            info_print(f"\nğŸ“Š å¹³å‡ç²¾åº¦åˆ†å¸ƒ:")
            info_print(f"  â€¢ å¹³å‡AP: {np.mean(average_precisions):.4f}")
            info_print(f"  â€¢ æœ€é«˜AP: {np.max(average_precisions):.4f}")
            info_print(f"  â€¢ æœ€ä½AP: {np.min(average_precisions):.4f}")
            info_print(f"  â€¢ æ ‡å‡†å·®: {np.std(average_precisions):.4f}")
    
    def print_sample_analysis(self, results: Dict[str, Any]):
        """
        æŒ‰æ ·æœ¬æ‰“å°MAPåˆ†æç»“æœ
        
        Args:
            results: MAPè¯„ä¼°ç»“æœ
        """
        info_print("\n" + "=" * 80)
        info_print("ğŸ“Š æ ·æœ¬çº§åˆ«MAPåˆ†æ")
        info_print("=" * 80)
        
        # æŒ‰å¹³å‡ç²¾åº¦æ’åº
        sorted_results = sorted(
            results['detailed_results'], 
            key=lambda x: x['average_precision'], 
            reverse=True
        )
        
        info_print("ğŸ” è¡¨ç°æœ€å¥½çš„æ ·æœ¬ (å‰5ä¸ª):")
        for i, result in enumerate(sorted_results[:5], 1):
            info_print(f"  {i}. è¡Œ {result['row_index'] + 1}: AP {result['average_precision']:.4f}")
            info_print(f"     æŸ¥è¯¢: {result['user_input'][:100]}...")
            info_print(f"     æ£€ç´¢åˆ†å—: {result['retrieved_count']}ä¸ª, å‚è€ƒåˆ†å—: {result['reference_count']}ä¸ª")
            info_print(f"     ç›¸å…³åˆ†å—æ•°: {result['relevant_chunks_count']}ä¸ª")
            info_print()
        
        info_print("ğŸ”» è¡¨ç°æœ€å·®çš„æ ·æœ¬ (å5ä¸ª):")
        for i, result in enumerate(sorted_results[-5:], 1):
            info_print(f"  {i}. è¡Œ {result['row_index'] + 1}: AP {result['average_precision']:.4f}")
            info_print(f"     æŸ¥è¯¢: {result['user_input'][:100]}...")
            info_print(f"     æ£€ç´¢åˆ†å—: {result['retrieved_count']}ä¸ª, å‚è€ƒåˆ†å—: {result['reference_count']}ä¸ª")
            info_print(f"     ç›¸å…³åˆ†å—æ•°: {result['relevant_chunks_count']}ä¸ª")
            info_print()
    
    def print_detailed_chunk_analysis(self, df: pd.DataFrame, max_samples: int = 3):
        """
        æ‰“å°è¯¦ç»†çš„åˆ†å—åˆ†æ
        
        Args:
            df: æ•°æ®DataFrame
            max_samples: æœ€å¤§æ˜¾ç¤ºæ ·æœ¬æ•°
        """
        info_print("\n" + "=" * 80)
        info_print("ğŸ” è¯¦ç»†åˆ†å—åˆ†æ")
        info_print("=" * 80)
        
        for idx, row in df.head(max_samples).iterrows():
            # å®‰å…¨çš„ç´¢å¼•è½¬æ¢
            sample_num = idx if isinstance(idx, int) else len(df.head(max_samples)) - list(df.head(max_samples).index).index(idx) if idx in df.head(max_samples).index else 1
            info_print(f"\nğŸ“‹ æ ·æœ¬ {sample_num + 1}:")
            
            # å®‰å…¨è·å–å­—ç¬¦ä¸²å€¼
            user_input_val = row.get('user_input', '')
            user_input = str(user_input_val) if user_input_val is not None and not pd.isna(user_input_val) else ""
            
            # ç¡®ä¿ç±»å‹è½¬æ¢ï¼šä»pandas Seriesè½¬æ¢ä¸ºList[str]
            retrieved_contexts_raw = row['retrieved_contexts']
            reference_contexts_raw = row['reference_contexts']
            
            retrieved_contexts = retrieved_contexts_raw if isinstance(retrieved_contexts_raw, list) else list(retrieved_contexts_raw) if retrieved_contexts_raw is not None else []
            reference_contexts = reference_contexts_raw if isinstance(reference_contexts_raw, list) else list(reference_contexts_raw) if reference_contexts_raw is not None else []
            
            info_print(f"æŸ¥è¯¢: {user_input}")
            info_print(f"æ£€ç´¢åˆ†å—æ•°: {len(retrieved_contexts)}")
            info_print(f"å‚è€ƒåˆ†å—æ•°: {len(reference_contexts)}")
            
            # è®¡ç®—å¹³å‡ç²¾åº¦å’Œè¯¦ç»†è¿‡ç¨‹
            average_precision, details = self.calculate_average_precision(
                user_input, retrieved_contexts, reference_contexts
            )
            
            info_print(f"\nğŸ“Š åˆ†å—ç›¸å…³æ€§åˆ†æ:")
            if 'chunk_relevance_scores' in details and details['chunk_relevance_scores']:
                for i, chunk_info in enumerate(details['chunk_relevance_scores']):
                    status = "âœ… ç›¸å…³" if chunk_info['is_relevant'] else "âŒ ä¸ç›¸å…³"
                    info_print(f"  ä½ç½®{chunk_info['position']}: {status} (ç›¸å…³æ€§: {chunk_info['relevance_score']:.4f})")
                    info_print(f"     æ£€ç´¢åˆ†å—: {chunk_info['chunk'][:100]}...")
                    if chunk_info['is_relevant']:
                        info_print(f"     æœ€ç›¸å…³å‚è€ƒåˆ†å—: {chunk_info['best_ref_chunk'][:80]}...")
                    info_print()
            else:
                info_print("  âŒ æ— ç›¸å…³åˆ†å—æˆ–æ£€ç´¢åˆ†å—æ•°æ®")
            
            info_print(f"ğŸ“Š å¹³å‡ç²¾åº¦è®¡ç®—:")
            if details['calculation_steps']:
                for step in details['calculation_steps']:
                    info_print(f"  ä½ç½®{step['position']}: ç²¾åº¦@{step['total_retrieved']} = {step['precision']:.4f}")
                info_print(f"  AP = {average_precision:.4f}")
            else:
                info_print(f"  âŒ æ— ç›¸å…³åˆ†å—ï¼ŒAP = 0.0000")
            
            info_print("-" * 60)
    
    def run_evaluation(self) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„MAPè¯„ä¼°
        
        Returns:
            Dict[str, Any]: MAPè¯„ä¼°ç»“æœ
        """
        info_print("ğŸš€ å¼€å§‹MAP RAGè¯„ä¼°")
        info_print("=" * 60)
        
        try:
            # 1. åŠ è½½æ•°æ®
            df = self.load_and_process_data()
            if df is None:
                return {"error": "æ•°æ®åŠ è½½å¤±è´¥"}
            
            # 2. è¿è¡ŒMAPè¯„ä¼°
            results = self.evaluate_map(df)
            
            # 3. æ‰“å°ç»“æœ
            self.print_detailed_analysis(results)
            self.print_sample_analysis(results)
            
            # 4. æ‰“å°è¯¦ç»†çš„åˆ†å—åˆ†æ
            self.print_detailed_chunk_analysis(df, max_samples=3)
            
            return results
            
        except Exception as e:
            error_print(f"âŒ MAPè¯„ä¼°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {"error": str(e)}


def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºé…ç½®
    config = EvaluationConfig(
        api_key=os.getenv("QWEN_API_KEY", "dummy_key"),
        api_base=os.getenv("QWEN_API_BASE", "dummy_base")
    )
    
    # åˆ›å»ºMAPè¯„ä¼°å™¨å¹¶è¿è¡Œè¯„ä¼°
    evaluator = MAPEvaluator(config)
    results = evaluator.run_evaluation()
    
    if "error" in results:
        error_print(f"âŒ MAPè¯„ä¼°å¤±è´¥: {results['error']}")
    else:
        info_print(f"\nğŸ‰ MAPè¯„ä¼°æˆåŠŸå®Œæˆï¼")
        info_print(f"ğŸ“Š æœ€ç»ˆMAPåˆ†æ•°: {results['map']:.4f}")


if __name__ == "__main__":
    main()
