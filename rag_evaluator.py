"""
åŸºäºRagas v0.3.2çš„LLMåº”ç”¨è¯„ä¼°ç³»ç»Ÿ
ä¸¥æ ¼æŒ‰ç…§Ragaså¼€æºæ¡†æ¶è¿›è¡Œè¯„ä¼°ï¼Œæ”¯æŒå¤šç§è¯„ä¼°æŒ‡æ ‡

æ¨¡å—åŒ–è®¾è®¡ï¼š
1. StableContextEntityRecall - ç¨³å®šçš„å®ä½“å¬å›ç‡å®ç°ï¼ˆä¸ä¾èµ–LLM JSONè¾“å‡ºï¼‰
2. CustomQwenEmbeddings - è‡ªå®šä¹‰Qwen EmbeddingåŒ…è£…å™¨
3. RagasEvaluator - Ragasè¯„ä¼°å™¨
4. ResultAnalyzer - ç»“æœåˆ†æ
5. MainController - ä¸»æ§åˆ¶å™¨

æ³¨æ„ï¼šDataLoaderã€TextProcessorå’ŒEvaluationConfigå·²ç§»è‡³read_chuck.pyæ¨¡å—

æ”¯æŒçš„è¯„ä¼°æŒ‡æ ‡ï¼ˆ8ä¸ªï¼‰ï¼š
- Faithfulness (å¿ å®åº¦) - éœ€è¦LLM
- AnswerRelevancy (å›ç­”ç›¸å…³æ€§) - éœ€è¦LLM
- ContextPrecision (ä¸Šä¸‹æ–‡ç²¾ç¡®åº¦) - éœ€è¦LLM
- ContextRecall (ä¸Šä¸‹æ–‡å¬å›ç‡) - éœ€è¦LLM
- ContextEntityRecall (ä¸Šä¸‹æ–‡å®ä½“å¬å›ç‡) - âœ… ç¨³å®šç‰ˆæœ¬ï¼ˆåŸºäºè§„åˆ™ï¼Œä¸éœ€è¦LLMï¼‰
- ContextRelevance (ä¸Šä¸‹æ–‡ç›¸å…³æ€§) - éœ€è¦LLM
- AnswerCorrectness (å›ç­”æ­£ç¡®æ€§) - éœ€è¦LLM
- AnswerSimilarity (å›ç­”ç›¸ä¼¼åº¦) - ä¸éœ€è¦LLMï¼ˆä½¿ç”¨Embeddingï¼‰

æ›´æ–°è¯´æ˜ï¼š
- 2025-10-28: ä¿®å¤ ContextEntityRecall æŒ‡æ ‡ï¼Œä½¿ç”¨è‡ªå®šä¹‰ç¨³å®šå®ç°æ›¿ä»£åŸç”ŸRagaså®ç°
- åŸç”Ÿ ContextEntityRecall å› LLM JSONè§£æä¸ç¨³å®šå¯¼è‡´40-50%å¤±è´¥ç‡
- æ–°å®ç°åŸºäºè§„åˆ™æå–å®ä½“ï¼ŒæˆåŠŸç‡æ¥è¿‘100%ï¼Œæ”¯æŒä¸­è‹±æ–‡
"""

import os
import json
import asyncio
import pandas as pd
import numpy as np
import re
import requests
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from pathlib import Path

# Import from read_chuck module
from read_chuck import EvaluationConfig, DataLoader, TextProcessor
from config import debug_print, verbose_print, info_print, error_print, verbose_info_print, debug_info_print, QUIET_MODE

# è®¾ç½®æ—¥å¿—çº§åˆ«ï¼Œå‡å°‘ä¸å¿…è¦çš„è¾“å‡º
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("requests").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("langchain").setLevel(logging.WARNING)

# è®¾ç½®Ragasç›¸å…³æ—¥å¿—çº§åˆ«
os.environ['RAGAS_QUIET'] = 'true'
os.environ['DISABLE_PROGRESS_BARS'] = 'true'

# Ragas v0.3.2 imports
from ragas import EvaluationDataset, evaluate
from ragas.metrics import (
    Faithfulness,
    AnswerRelevancy,
    ContextPrecision,
    ContextRecall,
    ContextEntityRecall,
    ContextRelevance,
    AnswerCorrectness,
    AnswerSimilarity
)
from ragas.llms import LangchainLLMWrapper
from ragas.embeddings import LangchainEmbeddingsWrapper

# LangChain imports
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.llms import Ollama

# Other imports
from dotenv import load_dotenv
from tabulate import tabulate

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from ragas.metrics.base import SingleTurnMetric, MetricType, MetricOutputType
from ragas.dataset_schema import SingleTurnSample
from typing import Set
from dataclasses import dataclass, field


class RagasMetricsConfig:
    """
    Ragas è¯„ä¼°æŒ‡æ ‡é…ç½®ç®¡ç†ç±»
    
    åŠŸèƒ½ï¼š
    1. ç®¡ç†å¯ç”¨çš„è¯„ä¼°æŒ‡æ ‡åˆ—è¡¨
    2. ä¿å­˜/åŠ è½½é…ç½®åˆ°JSONæ–‡ä»¶
    3. æä¾›é»˜è®¤é…ç½®
    """
    
    # é»˜è®¤å¯ç”¨çš„æŒ‡æ ‡
    DEFAULT_METRICS = [
        'context_recall',
        'context_precision',
        'context_entity_recall',
        'context_relevance',
        'faithfulness',
        'answer_relevancy',
        'answer_correctness',
        'answer_similarity'
    ]
    
    # å¿…é€‰æŒ‡æ ‡ï¼ˆä¸å¯ç¦ç”¨ï¼‰
    REQUIRED_METRICS = ['context_recall', 'context_precision']
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    CONFIG_FILE = "ragas_metrics_config.json"
    
    def __init__(self, enabled_metrics: List[str] = None):
        """
        åˆå§‹åŒ–é…ç½®
        
        Args:
            enabled_metrics: å¯ç”¨çš„æŒ‡æ ‡åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºNoneåˆ™ä½¿ç”¨å…¨éƒ¨æŒ‡æ ‡
        """
        self.enabled_metrics = enabled_metrics or self.DEFAULT_METRICS.copy()
        
        # ç¡®ä¿å¿…é€‰æŒ‡æ ‡å§‹ç»ˆå¯ç”¨
        for metric in self.REQUIRED_METRICS:
            if metric not in self.enabled_metrics:
                self.enabled_metrics.append(metric)
    
    def save(self) -> None:
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            config_data = {
                "enabled_metrics": self.enabled_metrics,
                "version": "1.0"
            }
            with open(self.CONFIG_FILE, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, indent=2, ensure_ascii=False)
            info_print(f"âœ… Ragasé…ç½®å·²ä¿å­˜åˆ° {self.CONFIG_FILE}")
        except Exception as e:
            error_print(f"âŒ ä¿å­˜Ragasé…ç½®å¤±è´¥: {e}")
    
    @classmethod
    def load(cls) -> 'RagasMetricsConfig':
        """
        ä»æ–‡ä»¶åŠ è½½é…ç½®
        
        Returns:
            RagasMetricsConfig: é…ç½®å¯¹è±¡
        """
        try:
            if os.path.exists(cls.CONFIG_FILE):
                with open(cls.CONFIG_FILE, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                enabled_metrics = config_data.get("enabled_metrics", cls.DEFAULT_METRICS)
                info_print(f"âœ… å·²åŠ è½½Ragasé…ç½®: {len(enabled_metrics)} ä¸ªæŒ‡æ ‡")
                return cls(enabled_metrics=enabled_metrics)
            else:
                info_print("â„¹ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return cls()
        except Exception as e:
            error_print(f"âŒ åŠ è½½Ragasé…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return cls()
    
    def is_enabled(self, metric_name: str) -> bool:
        """
        æ£€æŸ¥æŒ‡æ ‡æ˜¯å¦å¯ç”¨
        
        Args:
            metric_name: æŒ‡æ ‡åç§°
            
        Returns:
            bool: æ˜¯å¦å¯ç”¨
        """
        return metric_name in self.enabled_metrics


@dataclass
class StableContextEntityRecall(SingleTurnMetric):
    """
    ç¨³å®šçš„ä¸Šä¸‹æ–‡å®ä½“å¬å›ç‡å®ç°
    
    ä¸åŸç”Ÿ ContextEntityRecall çš„åŒºåˆ«ï¼š
    1. ä¸ä¾èµ– LLM æå–å®ä½“ï¼ˆé¿å… JSON è§£æé”™è¯¯ï¼‰
    2. ä½¿ç”¨è§„åˆ™å’Œæ­£åˆ™è¡¨è¾¾å¼æå–å®ä½“
    3. æ”¯æŒä¸­è‹±æ–‡å®ä½“æå–
    4. æˆåŠŸç‡æ¥è¿‘ 100%
    
    è®¡ç®—å…¬å¼ï¼š
    Context Entity Recall = |RCE âˆ© RE| / |RE|
    
    å…¶ä¸­ï¼š
    - REï¼šreferenceï¼ˆæ ‡å‡†ç­”æ¡ˆï¼‰ä¸­çš„å®ä½“é›†åˆ
    - RCEï¼šretrieved_contextsï¼ˆæ£€ç´¢ä¸Šä¸‹æ–‡ï¼‰ä¸­çš„å®ä½“é›†åˆ
    """
    
    name: str = "context_entity_recall"  # ä½¿ç”¨åŸç”ŸæŒ‡æ ‡åç§°ï¼Œä¿æŒå…¼å®¹æ€§
    _required_columns: Dict[MetricType, Set[str]] = field(
        default_factory=lambda: {
            MetricType.SINGLE_TURN: {"reference", "retrieved_contexts"}
        }
    )
    output_type: MetricOutputType = MetricOutputType.CONTINUOUS
    
    def init(self, run_config):
        """å®ç° Ragas åŸºç±»è¦æ±‚çš„ init æ–¹æ³•"""
        pass
    
    def _extract_entities_rule_based(self, text: str) -> Set[str]:
        """
        åŸºäºè§„åˆ™æå–å®ä½“ï¼ˆä¸ä½¿ç”¨ LLMï¼‰
        
        æå–ç­–ç•¥ï¼š
        1. ä¸“æœ‰åè¯ï¼ˆé¦–å­—æ¯å¤§å†™çš„è¿ç»­è¯ï¼‰
        2. æ•°å­—å’Œæ—¥æœŸ
        3. ä¸­æ–‡ä¸“æœ‰åè¯ï¼ˆé€šè¿‡å¸¸è§åç¼€è¯†åˆ«ï¼‰
        4. è‹±æ–‡ç¼©å†™
        """
        if not text or not isinstance(text, str):
            return set()
        
        entities = set()
        
        # 1. æå–è‹±æ–‡ä¸“æœ‰åè¯ï¼ˆè¿ç»­çš„é¦–å­—æ¯å¤§å†™å•è¯ï¼‰
        english_proper_nouns = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', text)
        entities.update(english_proper_nouns)
        
        # 2. æå–å•ä¸ªå¤§å†™å­—æ¯å•è¯ï¼ˆå¯èƒ½æ˜¯ç¼©å†™æˆ–ä¸“æœ‰åè¯ï¼‰
        single_caps = re.findall(r'\b[A-Z](?:\+\+|#|[A-Z]+)?\b', text)
        entities.update(single_caps)
        
        # 3. æå–æ•°å­—ï¼ˆåŒ…æ‹¬å¹´ä»½ã€ç‰ˆæœ¬å·ç­‰ï¼‰
        numbers = re.findall(r'\b\d+(?:\.\d+)*\b', text)
        entities.update(numbers)
        
        # 4. æå–ä¸­æ–‡ç»„ç»‡æœºæ„
        chinese_orgs = re.findall(r'[\u4e00-\u9fa5]{2,}(?:å…¬å¸|å¤§å­¦|å­¦é™¢|ç ”ç©¶é™¢|ä¸­å¿ƒ|éƒ¨é—¨|ç»„ç»‡)', text)
        entities.update(chinese_orgs)
        
        # 5. æå–ä¸­æ–‡äººåï¼ˆå¸¸è§å§“æ°å¼€å¤´çš„2-4å­—äººåï¼‰
        chinese_surnames = 'æ|ç‹|å¼ |åˆ˜|é™ˆ|æ¨|é»„|èµµ|å‘¨|å´|å¾|å­™|é©¬|æœ±|èƒ¡|éƒ­|ä½•|é«˜|æ—|ç½—|éƒ‘|æ¢|è°¢|å®‹|å”|è®¸|éŸ©|å†¯|é‚“|æ›¹|å½­|æ›¾|è‚–|ç”°|è‘£|è¢|æ½˜|äº|è’‹|è”¡|ä½™|æœ|å¶|ç¨‹|è‹|é­|å•|ä¸|ä»»|æ²ˆ|å§š|å¢|å§œ|å´”|é’Ÿ|è°­|é™†|æ±ª|èŒƒ|é‡‘|çŸ³|å»–|è´¾|å¤|éŸ¦|ä»˜|æ–¹|ç™½|é‚¹|å­Ÿ|ç†Š|ç§¦|é‚±|æ±Ÿ|å°¹|è–›|é—«|æ®µ|é›·|ä¾¯|é¾™|å²|é™¶|é»|è´º|é¡¾|æ¯›|éƒ|é¾š|é‚µ|ä¸‡|é’±|ä¸¥|è¦ƒ|æ­¦|æˆ´|è«|å­”|å‘|æ±¤'
        chinese_names = re.findall(f'(?:{chinese_surnames})[\u4e00-\u9fa5]{{1,3}}', text)
        entities.update(chinese_names)
        
        # 6. æå–ä¸­æ–‡åœ°å
        chinese_places = re.findall(r'[\u4e00-\u9fa5]{2,}(?:çœ|å¸‚|å¿|åŒº|é•‡|æ‘|è¡—|è·¯|å›½)', text)
        entities.update(chinese_places)
        
        # 7. æå–ç¼–ç¨‹è¯­è¨€ã€æŠ€æœ¯åç§°ç­‰
        tech_terms = re.findall(r'\b[A-Z][a-z]*(?:\.[a-z]+|Script|SQL|DB)?\b', text)
        entities.update(tech_terms)
        
        # 8. æå–æ‹¬å·ä¸­çš„å†…å®¹
        bracketed = re.findall(r'[ï¼ˆ(]([^ï¼‰)]{2,20})[ï¼‰)]', text)
        entities.update(bracketed)
        
        # è¿‡æ»¤ï¼šç§»é™¤è¿‡çŸ­æˆ–è¿‡é•¿çš„å®ä½“
        filtered_entities = {
            ent.strip() 
            for ent in entities 
            if ent and len(ent.strip()) >= 2 and len(ent.strip()) <= 50
        }
        
        # ç§»é™¤å¸¸è§åœç”¨è¯
        stopwords = {'çš„', 'äº†', 'å’Œ', 'ä¸', 'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'It'}
        filtered_entities = {
            ent for ent in filtered_entities 
            if ent.lower() not in stopwords
        }
        
        return filtered_entities
    
    def _compute_entity_recall(self, reference_entities: Set[str], context_entities: Set[str]) -> float:
        """è®¡ç®—å®ä½“å¬å›ç‡"""
        if not reference_entities:
            return 1.0
        
        found_entities = reference_entities & context_entities
        recall = len(found_entities) / len(reference_entities)
        
        return recall
    
    async def _single_turn_ascore(self, sample: SingleTurnSample, callbacks) -> float:
        """å¼‚æ­¥è®¡ç®—å•ä¸ªæ ·æœ¬çš„å®ä½“å¬å›ç‡ï¼ˆRagasæ¡†æ¶è°ƒç”¨çš„æ–¹æ³•ï¼‰"""
        return self._single_turn_score(sample)
    
    def _single_turn_score(self, sample: SingleTurnSample) -> float:
        """è®¡ç®—å•ä¸ªæ ·æœ¬çš„å®ä½“å¬å›ç‡"""
        # 1. æå–æ ‡å‡†ç­”æ¡ˆä¸­çš„å®ä½“
        reference = sample.reference or ""
        reference_entities = self._extract_entities_rule_based(reference)
        
        # 2. æå–æ£€ç´¢ä¸Šä¸‹æ–‡ä¸­çš„å®ä½“
        retrieved_contexts = sample.retrieved_contexts or []
        context_text = "\n".join([str(ctx) for ctx in retrieved_contexts])
        context_entities = self._extract_entities_rule_based(context_text)
        
        # 3. è®¡ç®—å¬å›ç‡
        score = self._compute_entity_recall(reference_entities, context_entities)
        
        return score


class OllamaEmbeddings:
    """Ollama EmbeddingåŒ…è£…å™¨ï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ï¼‰"""
    
    def __init__(self, ollama_url: str = "http://localhost:11434", model_name: str = "embeddinggemma:300m"):
        self.ollama_url = ollama_url.rstrip('/')
        self.model_name = model_name
        # æ€§èƒ½ä¼˜åŒ–ï¼šæ·»åŠ  embedding ç¼“å­˜
        self._embedding_cache = {}
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ä¸ºæ–‡æ¡£åˆ—è¡¨ç”Ÿæˆembeddingï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ï¼‰"""
        # ç¡®ä¿æ‰€æœ‰æ–‡æœ¬éƒ½æ˜¯å­—ç¬¦ä¸²
        texts = [str(text) for text in texts if str(text).strip()]
        if not texts:
            return []
        
        try:
            embeddings = []
            for text in texts:
                # æ€§èƒ½ä¼˜åŒ–ï¼šæ£€æŸ¥ç¼“å­˜
                cache_key = f"{self.model_name}:{text[:100]}"
                if cache_key in self._embedding_cache:
                    embeddings.append(self._embedding_cache[cache_key])
                    continue
                
                data = {
                    "model": self.model_name,
                    "prompt": text
                }
                
                response = requests.post(
                    f"{self.ollama_url}/api/embeddings",
                    json=data,
                    timeout=30
                )
                
                if response.status_code == 200:
                    result = response.json()
                    embedding = result["embedding"]
                    # åŠ å…¥ç¼“å­˜
                    self._embedding_cache[cache_key] = embedding
                    embeddings.append(embedding)
                else:
                    debug_info_print(f"Ollama Embedding APIé”™è¯¯: {response.status_code} - {response.text}")
                    # è¿”å›éšæœºembeddingä½œä¸ºfallback
                    import random
                    embeddings.append([random.random() for _ in range(2048)])  # embeddinggemma:300mé€šå¸¸æ˜¯2048ç»´
                    
            return embeddings
                
        except Exception as e:
            debug_info_print(f"Ollama Embeddingç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›éšæœºembeddingä½œä¸ºfallback
            import random
            return [[random.random() for _ in range(2048)] for _ in texts]
    
    def embed_query(self, text: str) -> List[float]:
        """ä¸ºå•ä¸ªæŸ¥è¯¢ç”Ÿæˆembedding"""
        return self.embed_documents([text])[0]
    
    async def aembed_documents(self, texts: List[str]) -> List[List[float]]:
        """å¼‚æ­¥ä¸ºæ–‡æ¡£åˆ—è¡¨ç”Ÿæˆembedding"""
        return self.embed_documents(texts)
    
    async def aembed_query(self, text: str) -> List[float]:
        """å¼‚æ­¥ä¸ºå•ä¸ªæŸ¥è¯¢ç”Ÿæˆembedding"""
        return self.embed_query(text)

class CustomQwenEmbeddings:
    """è‡ªå®šä¹‰Qwen EmbeddingåŒ…è£…å™¨ï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ï¼‰"""
    
    def __init__(self, api_key: str, api_base: str, model_name: str = "text-embedding-v1"):
        self.api_key = api_key
        self.api_base = api_base
        self.model_name = model_name
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        # æ€§èƒ½ä¼˜åŒ–ï¼šæ·»åŠ  embedding ç¼“å­˜
        self._embedding_cache = {}
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ä¸ºæ–‡æ¡£åˆ—è¡¨ç”Ÿæˆembeddingï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ï¼‰"""
        # ç¡®ä¿æ‰€æœ‰æ–‡æœ¬éƒ½æ˜¯å­—ç¬¦ä¸²
        texts = [str(text) for text in texts if str(text).strip()]
        if not texts:
            return []
        
        # æ€§èƒ½ä¼˜åŒ–ï¼šæ£€æŸ¥ç¼“å­˜
        embeddings = []
        texts_to_embed = []
        text_indices = []
        
        for i, text in enumerate(texts):
            cache_key = f"{self.model_name}:{text[:100]}"  # ä½¿ç”¨å‰100å­—ç¬¦ä½œä¸ºç¼“å­˜é”®
            if cache_key in self._embedding_cache:
                embeddings.append(self._embedding_cache[cache_key])
            else:
                texts_to_embed.append(text)
                text_indices.append(i)
        
        # å¦‚æœæ‰€æœ‰æ–‡æœ¬éƒ½å·²ç¼“å­˜ï¼Œç›´æ¥è¿”å›
        if not texts_to_embed:
            return embeddings
        
        try:
            data = {
                "input": texts_to_embed,
                "model": self.model_name
            }
            
            response = requests.post(
                f"{self.api_base}/embeddings",
                headers=self.headers,
                json=data,
                timeout=60  # æ·»åŠ è¶…æ—¶
            )
            
            if response.status_code == 200:
                result = response.json()
                new_embeddings = [item["embedding"] for item in result["data"]]
                
                # å°†æ–°ç”Ÿæˆçš„ embedding åŠ å…¥ç¼“å­˜
                for text, embedding in zip(texts_to_embed, new_embeddings):
                    cache_key = f"{self.model_name}:{text[:100]}"
                    self._embedding_cache[cache_key] = embedding
                
                # æŒ‰åŸå§‹é¡ºåºé‡ç»„ç»“æœ
                final_embeddings = [None] * len(texts)
                cached_idx = 0
                new_idx = 0
                for i in range(len(texts)):
                    if i in text_indices:
                        final_embeddings[i] = new_embeddings[new_idx]
                        new_idx += 1
                    else:
                        final_embeddings[i] = embeddings[cached_idx]
                        cached_idx += 1
                
                return final_embeddings
            else:
                debug_info_print(f"Embedding APIé”™è¯¯: {response.status_code} - {response.text}")
                # è¿”å›éšæœºembeddingä½œä¸ºfallback
                import random
                return [[random.random() for _ in range(1536)] for _ in texts]
                
        except Exception as e:
            debug_info_print(f"Embeddingç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›éšæœºembeddingä½œä¸ºfallback
            import random
            return [[random.random() for _ in range(1536)] for _ in texts]
    
    def embed_query(self, text: str) -> List[float]:
        """ä¸ºå•ä¸ªæŸ¥è¯¢ç”Ÿæˆembedding"""
        return self.embed_documents([text])[0]
    
    async def aembed_documents(self, texts: List[str]) -> List[List[float]]:
        """å¼‚æ­¥ä¸ºæ–‡æ¡£åˆ—è¡¨ç”Ÿæˆembedding"""
        return self.embed_documents(texts)
    
    async def aembed_query(self, text: str) -> List[float]:
        """å¼‚æ­¥ä¸ºå•ä¸ªæŸ¥è¯¢ç”Ÿæˆembedding"""
        return self.embed_query(text)

class RagasEvaluator:
    """Ragasè¯„ä¼°å™¨æ¨¡å—"""
    
    def __init__(self, config: EvaluationConfig):
        self.config = config
        self.llm = None
        self.embeddings = None
        self.ragas_llm = None
        self.ragas_embeddings = None
    
    def setup_environment(self):
        """è®¾ç½®LLMå’ŒEmbeddingsç¯å¢ƒ"""
        verbose_info_print("ğŸ”§ è®¾ç½®ç¯å¢ƒ...")
        
        # æ ¹æ®é…ç½®é€‰æ‹©LLMå’ŒEmbeddingæ¨¡å‹
        if hasattr(self.config, 'use_ollama') and self.config.use_ollama:
            # ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼šæœ¬åœ°embedding + äº‘ç«¯LLMï¼ˆæ··åˆæ¨¡å¼ï¼‰
            verbose_info_print(f"ğŸ”§ ä½¿ç”¨æœ¬åœ°æ¨¡å‹é…ç½®ï¼ˆæ··åˆæ¨¡å¼ï¼‰")
            
            # åˆ›å»ºäº‘ç«¯Qwen LLMå®ä¾‹ï¼ˆå› ä¸ºæœ¬åœ°æ²¡æœ‰LLMæ¨¡å‹ï¼‰
            # ä½¿ç”¨ä¸¥æ ¼çš„é‡‡æ ·å‚æ•°ä»¥è·å¾—æœ€ç¨³å®šçš„ JSON è¾“å‡º
            # æ³¨æ„ï¼šQwen API è¦æ±‚å‚æ•°æ˜¾å¼æŒ‡å®šï¼Œä¸èƒ½ä½¿ç”¨ model_kwargs
            self.llm = ChatOpenAI(
                model=self.config.model_name,
                openai_api_key=self.config.api_key,
                openai_api_base=self.config.api_base,
                temperature=self.config.temperature,
                max_tokens=self.config.max_tokens,  # æ˜¾å¼æŒ‡å®š
                top_p=self.config.top_p,  # æ˜¾å¼æŒ‡å®š
            )
            
            # åˆ›å»ºæœ¬åœ°Ollama Embeddingå®ä¾‹
            verbose_info_print(f"ğŸ”§ ä½¿ç”¨æœ¬åœ°Ollama embeddingæ¨¡å‹: {self.config.ollama_embedding_model}")
            self.embeddings = OllamaEmbeddings(
                ollama_url=self.config.ollama_url,
                model_name=self.config.ollama_embedding_model
            )
            custom_embeddings = self.embeddings
            
            verbose_info_print(f"ğŸ¤– ä½¿ç”¨äº‘ç«¯Qwen LLMæ¨¡å‹: {self.config.model_name}")
            verbose_info_print(f"ğŸ“Š æ··åˆæ¨¡å¼ï¼šæœ¬åœ°embedding + äº‘ç«¯LLM")
        else:
            # ä½¿ç”¨äº‘ç«¯Qwenæ¨¡å‹
            verbose_info_print(f"ğŸ”§ ä½¿ç”¨äº‘ç«¯Qwenæ¨¡å‹")
            
            # åˆ›å»ºQwen LLMå®ä¾‹
            # ä½¿ç”¨ä¸¥æ ¼çš„é‡‡æ ·å‚æ•°ä»¥è·å¾—æœ€ç¨³å®šçš„ JSON è¾“å‡º
            # æ³¨æ„ï¼šQwen API è¦æ±‚å‚æ•°æ˜¾å¼æŒ‡å®šï¼Œä¸èƒ½ä½¿ç”¨ model_kwargs
            self.llm = ChatOpenAI(
                model=self.config.model_name,
                openai_api_key=self.config.api_key,
                openai_api_base=self.config.api_base,
                temperature=self.config.temperature,
                max_tokens=self.config.max_tokens,  # æ˜¾å¼æŒ‡å®š
                top_p=self.config.top_p,  # æ˜¾å¼æŒ‡å®š
            )
            
            # åˆ›å»ºQwen Embeddingå®ä¾‹
            verbose_info_print(f"ğŸ”§ ä½¿ç”¨äº‘ç«¯Qwen embeddingæ¨¡å‹: {self.config.embedding_model}")
            self.embeddings = OpenAIEmbeddings(
                openai_api_key=self.config.api_key,
                openai_api_base=self.config.api_base,
                model=self.config.embedding_model
            )
            custom_embeddings = CustomQwenEmbeddings(
                self.config.api_key, 
                self.config.api_base, 
                self.config.embedding_model
            )
            
            verbose_info_print(f"ğŸ¤– ä½¿ç”¨äº‘ç«¯Qwen LLMæ¨¡å‹: {self.config.model_name}")
        
        # åˆ›å»ºRagasåŒ…è£…å™¨
        # ç¡®è®¤é‡‡æ ·å‚æ•°å·²æ­£ç¡®è®¾ç½®ï¼ˆæé«˜ Ragas è§£æå™¨æˆåŠŸç‡ï¼‰
        verbose_info_print(f"ğŸ¯ LLM é‡‡æ ·å‚æ•°: temperature={self.llm.temperature}, top_p={getattr(self.llm, 'top_p', 'N/A')}, max_tokens={getattr(self.llm, 'max_tokens', 'N/A')}")
        
        self.ragas_llm = LangchainLLMWrapper(self.llm)
        self.ragas_embeddings = LangchainEmbeddingsWrapper(custom_embeddings)
        
        verbose_info_print("âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ")
    
    def create_ragas_dataset(self, df: pd.DataFrame, text_processor: TextProcessor) -> EvaluationDataset:
        """
        åˆ›å»ºRagasè¯„ä¼°æ•°æ®é›†
        
        Args:
            df: å¤„ç†åçš„DataFrame
            text_processor: æ–‡æœ¬å¤„ç†å™¨
            
        Returns:
            EvaluationDataset: Ragasè¯„ä¼°æ•°æ®é›†
        """
        verbose_info_print("ğŸ“Š åˆ›å»ºRagasè¯„ä¼°æ•°æ®é›†...")
        
        # å‡†å¤‡ç”¨äºRagasçš„æ•°æ®
        ragas_df = df.copy()
        ragas_df['reference'] = df['reference']
        ragas_df['reference_contexts'] = df['reference_contexts']
        
        # ç¡®ä¿retrieved_contextsæ˜¯åˆ—è¡¨æ ¼å¼
        ragas_df['retrieved_contexts'] = ragas_df['retrieved_contexts'].apply(text_processor.process_contexts)
        
        # ç¡®ä¿reference_contextsä¹Ÿæ˜¯åˆ—è¡¨æ ¼å¼
        def safe_process_contexts(contexts):
            if isinstance(contexts, list):
                return contexts
            else:
                return text_processor.process_contexts(contexts)
        
        ragas_df['reference_contexts'] = ragas_df['reference_contexts'].apply(safe_process_contexts)
        
        # è¿‡æ»¤æ‰ç©ºè¡Œ
        verbose_info_print("ğŸ” è¿‡æ»¤ç©ºè¡Œæ•°æ®...")
        filtered_rows = []
        for i in range(len(ragas_df)):
            retrieved_contexts = ragas_df['retrieved_contexts'].iloc[i]
            reference_contexts = ragas_df['reference_contexts'].iloc[i]
            user_input = ragas_df['user_input'].iloc[i] if 'user_input' in ragas_df.columns else ""
            response = ragas_df['response'].iloc[i] if 'response' in ragas_df.columns else ""
            
            if not text_processor.is_empty_row_data(retrieved_contexts, reference_contexts, user_input, response):
                filtered_rows.append(i)
                debug_info_print(f"ä¿ç•™è¡Œ {i+1}: retrieved_contexts={len(retrieved_contexts)}ä¸ªç‰‡æ®µ, reference_contexts={len(reference_contexts)}ä¸ªç‰‡æ®µ")
            else:
                debug_info_print(f"è·³è¿‡è¡Œ {i+1}: æ£€æµ‹åˆ°ç©ºè¡Œæ•°æ®")
        
        # åˆ›å»ºè¿‡æ»¤åçš„æ•°æ®
        ragas_df = ragas_df.iloc[filtered_rows].copy()
        verbose_info_print(f"è¿‡æ»¤åçš„æ•°æ®é›†è¡Œæ•°: {len(ragas_df)}")
        
        # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½æœ‰æœ‰æ•ˆå€¼
        ragas_df['reference'] = ragas_df['reference'].apply(
            lambda x: x if pd.notna(x) and str(x).strip() else "æ— æ ‡å‡†ç­”æ¡ˆ"
        )
        ragas_df['user_input'] = ragas_df['user_input'].apply(
            lambda x: x if pd.notna(x) and str(x).strip() else "æ— ç”¨æˆ·è¾“å…¥"
        )
        ragas_df['response'] = ragas_df['response'].apply(
            lambda x: x if pd.notna(x) and str(x).strip() else "æ— å›ç­”"
        )
        
        # ç¡®ä¿contextså­—æ®µä¸ä¸ºç©ºåˆ—è¡¨
        ragas_df['retrieved_contexts'] = ragas_df['retrieved_contexts'].apply(
            lambda x: x if x else ["æ— æ£€ç´¢ä¸Šä¸‹æ–‡"]
        )
        ragas_df['reference_contexts'] = ragas_df['reference_contexts'].apply(
            lambda x: x if x else ["æ— æ ‡å‡†ç­”æ¡ˆä¸Šä¸‹æ–‡"]
        )
        
        dataset = EvaluationDataset.from_pandas(ragas_df)
        info_print(f"âœ… æˆåŠŸåˆ›å»ºåŒ…å« {len(dataset)} ä¸ªæ ·æœ¬çš„è¯„ä¼°æ•°æ®é›†")
        
        return dataset
    
    def create_metrics(self) -> List[Any]:
        """
        åˆ›å»ºRagasè¯„ä¼°æŒ‡æ ‡ï¼ˆæ ¹æ®é…ç½®åŠ¨æ€é€‰æ‹©ï¼‰
        
        Returns:
            List[Any]: è¯„ä¼°æŒ‡æ ‡åˆ—è¡¨
        """
        info_print("ğŸ“ˆ è®¾ç½®è¯„ä¼°æŒ‡æ ‡...")
        
        # åŠ è½½é…ç½®
        config = RagasMetricsConfig.load()
        
        # æŒ‡æ ‡æ˜ å°„è¡¨ï¼ˆæŒ‡æ ‡åç§° -> æŒ‡æ ‡å¯¹è±¡åˆ›å»ºå‡½æ•°ï¼‰
        metrics_map = {
            'faithfulness': lambda: Faithfulness(),
            'answer_relevancy': lambda: AnswerRelevancy(embeddings=self.ragas_embeddings),
            'context_precision': lambda: ContextPrecision(),
            'context_recall': lambda: ContextRecall(),
            'context_entity_recall': lambda: StableContextEntityRecall(),
            'context_relevance': lambda: ContextRelevance(),
            'answer_correctness': lambda: AnswerCorrectness(embeddings=self.ragas_embeddings),
            'answer_similarity': lambda: AnswerSimilarity(embeddings=self.ragas_embeddings)
        }
        
        # æ ¹æ®é…ç½®åˆ›å»ºå¯ç”¨çš„æŒ‡æ ‡
        metrics = []
        enabled_metrics_names = []
        
        for metric_name in config.enabled_metrics:
            if metric_name in metrics_map:
                metrics.append(metrics_map[metric_name]())
                enabled_metrics_names.append(metric_name)
            else:
                info_print(f"âš ï¸ æœªçŸ¥æŒ‡æ ‡: {metric_name}")
        
        # å¦‚æœæ²¡æœ‰å¯ç”¨ä»»ä½•æŒ‡æ ‡ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        if not metrics:
            info_print("âš ï¸ æœªå¯ç”¨ä»»ä½•æŒ‡æ ‡ï¼Œä½¿ç”¨å…¨éƒ¨é»˜è®¤æŒ‡æ ‡")
            metrics = [factory() for factory in metrics_map.values()]
            enabled_metrics_names = list(metrics_map.keys())
        
        info_print(f"âœ… å·²è®¾ç½® {len(metrics)} ä¸ªè¯„ä¼°æŒ‡æ ‡: {', '.join(enabled_metrics_names)}")
        return metrics
    
    async def evaluate(self, dataset: EvaluationDataset) -> Any:
        """
        è¿è¡ŒRagasè¯„ä¼°
        
        Args:
            dataset: Ragasè¯„ä¼°æ•°æ®é›†
            
        Returns:
            Any: è¯„ä¼°ç»“æœ
        """
        info_print("ğŸ” å¼€å§‹Ragasè¯„ä¼°...")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥å‡å°‘æ—¥å¿—è¾“å‡º
        import os
        os.environ['RAGAS_QUIET'] = 'true'
        os.environ['DISABLE_PROGRESS_BARS'] = 'true'
        
        # é™ä½æ—¥å¿—çº§åˆ«ä»¥å‡å°‘å¹²æ‰°
        import logging
        logging.getLogger('ragas').setLevel(logging.ERROR)
        
        try:
            metrics = self.create_metrics()
            info_print(f"ğŸ“Š ä½¿ç”¨ {len(metrics)} ä¸ªè¯„ä¼°æŒ‡æ ‡...")
            
            # æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨å¹¶å‘å’Œæ‰¹å¤„ç†åŠ é€Ÿè¯„ä¼°
            from ragas.run_config import RunConfig
            run_config = RunConfig(
                max_workers=self.config.max_workers,  # æœ€å¤§å¹¶å‘æ•°
                timeout=300,  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            )
            
            info_print(f"âš¡ æ€§èƒ½ä¼˜åŒ–: max_workers={self.config.max_workers}, batch_size={self.config.batch_size}")
            
            # è¿è¡Œè¯„ä¼°ï¼ˆæ·»åŠ å¹¶å‘å’Œæ‰¹å¤„ç†å‚æ•°ï¼‰
            results = evaluate(
                dataset, 
                metrics, 
                llm=self.ragas_llm,
                run_config=run_config,
                batch_size=self.config.batch_size  # æ‰¹å¤„ç†å¤§å°
            )
            info_print("âœ… Ragasè¯„ä¼°å®Œæˆ")
            return results
        except Exception as e:
            error_msg = str(e)
            info_print(f"âš ï¸ Ragasè¯„ä¼°é‡åˆ°é”™è¯¯: {error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è§£æå™¨é”™è¯¯
            if "parser" in error_msg.lower() or "parse" in error_msg.lower():
                info_print("ğŸ”„ æ£€æµ‹åˆ°è§£æå™¨é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨ç®€åŒ–çš„è¯„ä¼°æŒ‡æ ‡...")
                
                # ä½¿ç”¨æœ€ç¨³å®šçš„æŒ‡æ ‡é‡è¯•
                try:
                    simple_metrics = [
                        Faithfulness(),  # å¿ å®åº¦ï¼ˆä¸éœ€è¦ LLMï¼‰
                        ContextPrecision(),  # ä¸Šä¸‹æ–‡ç²¾ç¡®åº¦ï¼ˆä¸éœ€è¦ LLMï¼‰
                        ContextRecall(),  # ä¸Šä¸‹æ–‡å¬å›ç‡ï¼ˆä¸éœ€è¦ LLMï¼‰
                    ]
                    info_print("ğŸ“Š ä½¿ç”¨ç®€åŒ–çš„è¯„ä¼°æŒ‡æ ‡ï¼ˆä»…ä½¿ç”¨ä¸éœ€è¦ LLM çš„æŒ‡æ ‡ï¼‰...")
                    results = evaluate(dataset, simple_metrics, llm=self.ragas_llm)
                    info_print("âœ… ç®€åŒ–è¯„ä¼°å®Œæˆ")
                    return results
                except Exception as e2:
                    info_print(f"âŒ ç®€åŒ–è¯„ä¼°ä¹Ÿå¤±è´¥: {e2}")
                    import traceback
                    traceback.print_exc()
            
            # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›fallbackç»“æœ
            info_print("ğŸ”„ ä½¿ç”¨ fallback æ¨¡å¼...")
            return self._create_fallback_results(dataset)
    
    def _create_fallback_results(self, dataset: EvaluationDataset) -> Dict[str, Any]:
        """
        åˆ›å»ºfallbackè¯„ä¼°ç»“æœ
        
        Args:
            dataset: è¯„ä¼°æ•°æ®é›†
            
        Returns:
            Dict[str, Any]: åŸºæœ¬çš„è¯„ä¼°ç»“æœ
        """
        info_print("ğŸ”„ åˆ›å»ºfallbackè¯„ä¼°ç»“æœ...")
        
        # è®¡ç®—åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        total_samples = len(dataset)
        
        # åˆ›å»ºåŸºæœ¬çš„è¯„ä¼°ç»“æœ
        fallback_results = {
            'faithfulness': 0.5,  # é»˜è®¤ä¸­ç­‰åˆ†æ•°
            'answer_relevancy': 0.5,
            'context_precision': 0.5,
            'context_recall': 0.5,
            'context_entity_recall': 0.5,
            'context_relevance': 0.5,
            'answer_correctness': 0.5,
            'answer_similarity': 0.5,
            'total_samples': total_samples,
            'fallback_mode': True,
            'error_message': 'Ragasè¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨fallbackç»“æœ'
        }
        
        info_print(f"âœ… Fallbackç»“æœåˆ›å»ºå®Œæˆï¼Œæ ·æœ¬æ•°: {total_samples}")
        return fallback_results

class ResultAnalyzer:
    """ç»“æœåˆ†ææ¨¡å—"""
    
    def __init__(self):
        self.results = None
    
    def analyze_results(self, results: Any) -> Dict[str, Any]:
        """
        åˆ†æè¯„ä¼°ç»“æœ
        
        Args:
            results: Ragasè¯„ä¼°ç»“æœ
            
        Returns:
            Dict[str, Any]: åˆ†æåçš„ç»“æœå­—å…¸
        """
        info_print("ğŸ“Š åˆ†æè¯„ä¼°ç»“æœ...")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯fallbackç»“æœ
        if isinstance(results, dict) and results.get('fallback_mode', False):
            info_print("âš ï¸ æ£€æµ‹åˆ°fallbackç»“æœï¼Œä½¿ç”¨ç®€åŒ–åˆ†æ")
            analysis = {
                'faithfulness': results.get('faithfulness', 0.5),
                'answer_relevancy': results.get('answer_relevancy', 0.5),
                'context_precision': results.get('context_precision', 0.5),
                'context_recall': results.get('context_recall', 0.5),
                'context_entity_recall': results.get('context_entity_recall', 0.5),
                'context_relevance': results.get('nv_context_relevance', 0.5),
                'answer_correctness': results.get('answer_correctness', 0.5),
                'answer_similarity': results.get('answer_similarity', 0.5),
                'raw_results': results,
                'fallback_mode': True,
                'error_message': results.get('error_message', 'è¯„ä¼°å¤±è´¥')
            }
            info_print("âœ… Fallbackç»“æœåˆ†æå®Œæˆ")
            return analysis
        
        # æå–ç»“æœå­—å…¸
        if hasattr(results, '_repr_dict'):
            results_dict = results._repr_dict
        elif hasattr(results, '__dict__') and '_repr_dict' in results.__dict__:
            results_dict = results.__dict__['_repr_dict']
        else:
            results_dict = str(results)
        
        # æå–å„é¡¹æŒ‡æ ‡ - ä½¿ç”¨å®é™…çš„å­—æ®µå
        analysis = {
            'faithfulness': results_dict.get('faithfulness') if isinstance(results_dict, dict) else None,
            'answer_relevancy': results_dict.get('answer_relevancy') if isinstance(results_dict, dict) else None,
            'context_precision': results_dict.get('context_precision') if isinstance(results_dict, dict) else None,
            'context_recall': results_dict.get('context_recall') if isinstance(results_dict, dict) else None,
            'context_entity_recall': results_dict.get('context_entity_recall') if isinstance(results_dict, dict) else None,
            'context_relevance': results_dict.get('nv_context_relevance') if isinstance(results_dict, dict) else None,  # ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
            'answer_correctness': results_dict.get('answer_correctness') if isinstance(results_dict, dict) else None,
            'answer_similarity': results_dict.get('answer_similarity') if isinstance(results_dict, dict) else None,
            'raw_results': results,
            'fallback_mode': False
        }
        
        info_print("âœ… ç»“æœåˆ†æå®Œæˆ")
        return analysis
    
    def display_results(self, analysis: Dict[str, Any]):
        """
        æ˜¾ç¤ºè¯„ä¼°ç»“æœ
        
        Args:
            analysis: åˆ†æåçš„ç»“æœå­—å…¸
        """
        info_print("\n" + "=" * 60)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯fallbackæ¨¡å¼
        if analysis.get('fallback_mode', False):
            info_print("âš ï¸ Ragasè¯„ä¼°ç»“æœ (Fallbackæ¨¡å¼)")
            info_print("=" * 60)
            info_print(f"âŒ è¯„ä¼°é”™è¯¯: {analysis.get('error_message', 'æœªçŸ¥é”™è¯¯')}")
            info_print("ğŸ”„ ä½¿ç”¨é»˜è®¤è¯„ä¼°åˆ†æ•°")
        else:
            info_print("ğŸ“Š Ragasè¯„ä¼°ç»“æœ")
            info_print("=" * 60)
        
        # åˆ›å»ºç»“æœè¡¨æ ¼
        results_data = []
        metrics_info = [
            ("Faithfulness", "å¿ å®åº¦", analysis.get('faithfulness')),
            ("Answer Relevancy", "å›ç­”ç›¸å…³æ€§", analysis.get('answer_relevancy')),
            ("Context Precision", "ä¸Šä¸‹æ–‡ç²¾ç¡®åº¦", analysis.get('context_precision')),
            ("Context Recall", "ä¸Šä¸‹æ–‡å¬å›ç‡", analysis.get('context_recall')),
            ("Context Entity Recall", "ä¸Šä¸‹æ–‡å®ä½“å¬å›ç‡", analysis.get('context_entity_recall')),
            ("Context Relevance", "ä¸Šä¸‹æ–‡ç›¸å…³æ€§", analysis.get('context_relevance')),
            ("Answer Correctness", "å›ç­”æ­£ç¡®æ€§", analysis.get('answer_correctness')),
            ("Answer Similarity", "å›ç­”ç›¸ä¼¼åº¦", analysis.get('answer_similarity'))
        ]
        
        for metric_name, chinese_name, value in metrics_info:
            if value is not None:
                status = "âš ï¸" if analysis.get('fallback_mode', False) else "âœ…"
                results_data.append([
                    f"{status} {metric_name}",
                    chinese_name,
                    f"{value:.4f}",
                    f"{value*100:.1f}%"
                ])
            else:
                results_data.append([
                    f"âŒ {metric_name}",
                    chinese_name,
                    "è¯„ä¼°å¤±è´¥",
                    "N/A"
                ])
        
        # ä½¿ç”¨tabulateæ˜¾ç¤ºè¡¨æ ¼
        try:
            headers = ["æŒ‡æ ‡åç§°", "ä¸­æ–‡åç§°", "åˆ†æ•°", "ç™¾åˆ†æ¯”"]
            info_print(tabulate(results_data, headers=headers, tablefmt="grid", stralign="left"))
        except:
            # ç®€å•è¡¨æ ¼æ ¼å¼
            info_print(f"{'æŒ‡æ ‡åç§°':<25} {'ä¸­æ–‡åç§°':<15} {'åˆ†æ•°':<10} {'ç™¾åˆ†æ¯”':<10}")
            info_print("-" * 70)
            for row in results_data:
                info_print(f"{row[0]:<25} {row[1]:<15} {row[2]:<10} {row[3]:<10}")
        
        # æ˜¾ç¤ºè¯¦ç»†åˆ†æ
        info_print(f"\nğŸ“‹ è¯¦ç»†åˆ†æ:")
        valid_metrics = [item for item in metrics_info if item[2] is not None]
        if valid_metrics:
            avg_score = sum(item[2] for item in valid_metrics) / len(valid_metrics)
            info_print(f"  â€¢ å¹³å‡åˆ†æ•°: {avg_score:.4f} ({avg_score*100:.1f}%)")
            info_print(f"  â€¢ æœ‰æ•ˆæŒ‡æ ‡æ•°: {len(valid_metrics)}/{len(metrics_info)}")
            
            if analysis.get('fallback_mode', False):
                info_print(f"  â€¢ âš ï¸ æ³¨æ„: å½“å‰ä¸ºfallbackæ¨¡å¼ï¼Œåˆ†æ•°ä¸ºé»˜è®¤å€¼")
            else:
                # æ‰¾å‡ºæœ€é«˜å’Œæœ€ä½åˆ†æ•°
                best_metric = max(valid_metrics, key=lambda x: x[2])
                worst_metric = min(valid_metrics, key=lambda x: x[2])
                info_print(f"  â€¢ æœ€é«˜åˆ†æ•°: {best_metric[1]} ({best_metric[2]:.4f})")
                info_print(f"  â€¢ æœ€ä½åˆ†æ•°: {worst_metric[1]} ({worst_metric[2]:.4f})")
        else:
            info_print("  â€¢ æ‰€æœ‰æŒ‡æ ‡è¯„ä¼°å¤±è´¥")

class MainController:
    """ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, config: EvaluationConfig):
        self.config = config
        self.data_loader = DataLoader(config)
        self.text_processor = TextProcessor(config)
        self.ragas_evaluator = RagasEvaluator(config)
        self.result_analyzer = ResultAnalyzer()
    
    async def run_evaluation(self) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„è¯„ä¼°æµç¨‹
        
        Returns:
            Dict[str, Any]: è¯„ä¼°ç»“æœ
        """
        info_print("ğŸš€ å¼€å§‹Ragas LLMåº”ç”¨è¯„ä¼°")
        info_print("=" * 60)
        
        try:
            # 1. åŠ è½½æ•°æ®
            df = self.data_loader.load_excel_data()
            if df is None:
                return {"error": "æ•°æ®åŠ è½½å¤±è´¥"}
            
            # 2. éªŒè¯æ•°æ®
            if not self.data_loader.validate_data(df):
                return {"error": "æ•°æ®éªŒè¯å¤±è´¥"}
            
            # 3. æ•°æ®é¢„å¤„ç†
            info_print("ğŸ”§ æ•°æ®é¢„å¤„ç†...")
            df = self.text_processor.parse_context_columns(df)
            
            # 4. æ™ºèƒ½é€‰æ‹©æ ‡å‡†ç­”æ¡ˆ
            info_print("ğŸ” æ™ºèƒ½é€‰æ‹©æ ‡å‡†ç­”æ¡ˆ...")
            df['final_reference'] = df['reference']
            df['final_reference_contexts'] = df['reference_contexts']
            
            # æ˜¾ç¤ºæ•°æ®æ ·æœ¬ä¿¡æ¯
            info_print(f"\nğŸ“‹ æ•°æ®æ ·æœ¬ä¿¡æ¯:")
            info_print(f"  â€¢ æ€»è¡Œæ•°: {len(df)}")
            info_print(f"  â€¢ ç”¨æˆ·è¾“å…¥ç¤ºä¾‹: {df['user_input'].iloc[0][:100]}...")
            info_print(f"  â€¢ å›ç­”ç¤ºä¾‹: {df['response'].iloc[0][:100]}...")
            info_print(f"  â€¢ æ ‡å‡†ç­”æ¡ˆç¤ºä¾‹: {df['final_reference'].iloc[0][:100]}...")
            
            # 5. è®¾ç½®ç¯å¢ƒ
            self.ragas_evaluator.setup_environment()
            
            # 6. åˆ›å»ºRagasæ•°æ®é›†
            dataset = self.ragas_evaluator.create_ragas_dataset(df, self.text_processor)
            
            # 7. è¿è¡Œè¯„ä¼°
            results = await self.ragas_evaluator.evaluate(dataset)
            
            # 8. åˆ†æç»“æœ
            analysis = self.result_analyzer.analyze_results(results)
            
            # 9. æ˜¾ç¤ºç»“æœ
            self.result_analyzer.display_results(analysis)
            
            return analysis
            
        except Exception as e:
            info_print(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {"error": str(e)}
        
        finally:
            info_print("âœ… è¯„ä¼°å®Œæˆï¼")

async def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºé…ç½®
    config = EvaluationConfig(
        api_key=os.getenv("QWEN_API_KEY"),
        api_base=os.getenv("QWEN_API_BASE"),
        model_name=os.getenv("QWEN_MODEL_NAME", "qwen-plus"),
        embedding_model=os.getenv("QWEN_EMBEDDING_MODEL", "text-embedding-v1")
    )
    
    # éªŒè¯é…ç½®
    if not config.api_key or not config.api_base:
        info_print("âŒ è¯·è®¾ç½®QWEN_API_KEYå’ŒQWEN_API_BASEç¯å¢ƒå˜é‡")
        return
    
    # åˆ›å»ºä¸»æ§åˆ¶å™¨å¹¶è¿è¡Œè¯„ä¼°
    controller = MainController(config)
    results = await controller.run_evaluation()
    
    if "error" in results:
        info_print(f"âŒ è¯„ä¼°å¤±è´¥: {results['error']}")
    else:
        info_print(f"\nğŸ‰ è¯„ä¼°æˆåŠŸå®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main())
