"""
RAGè¯„ä¼°æŒ‡æ ‡NDCG (Normalized Discounted Cumulative Gain) å®ç°
ç”¨äºè®¡ç®—æ£€ç´¢ç³»ç»Ÿä¸­ç›¸å…³åˆ†å—çš„æ’åºè´¨é‡

åŠŸèƒ½ï¼š
1. åŠ è½½RAGæ ·æœ¬æ•°æ®å’Œåˆ†å—æ•°æ®
2. ä½¿ç”¨BM25ç®—æ³•åˆ¤æ–­åˆ†å—ç›¸å…³æ€§
3. è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„DCGå’ŒIDCG
4. è®¡ç®—NDCGæŒ‡æ ‡
5. æŒ‰æ ·æœ¬åˆ†ç»„æ˜¾ç¤ºè®¡ç®—è¿‡ç¨‹
"""

import os
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
from config import debug_print, verbose_print, info_print, error_print, QUIET_MODE
from read_chuck import EvaluationConfig, DataLoader, TextProcessor
from BM25_evaluate import BM25Evaluator, BM25, find_relevant_chunks, is_chunk_relevant


class NDCGEvaluator:
    """NDCG (Normalized Discounted Cumulative Gain) è¯„ä¼°å™¨"""
    
    def __init__(self, config: EvaluationConfig):
        """
        åˆå§‹åŒ–NDCGè¯„ä¼°å™¨
        
        Args:
            config: è¯„ä¼°é…ç½®
        """
        self.config = config
        self.data_loader = DataLoader(config)
        self.text_processor = TextProcessor(config)
        self.bm25_evaluator = BM25Evaluator(config)
        
        # ç›¸å…³æ€§é˜ˆå€¼
        self.relevance_threshold = float(os.getenv("SIMILARITY_THRESHOLD", "0.5"))
        
        info_print("ğŸ”§ NDCGè¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ")
        info_print(f"ğŸ“Š ç›¸å…³æ€§é˜ˆå€¼: {self.relevance_threshold}")
    
    def load_and_process_data(self) -> Optional[pd.DataFrame]:
        """
        åŠ è½½å’Œå¤„ç†RAGæ ·æœ¬æ•°æ®
        
        Returns:
            pd.DataFrame: å¤„ç†åçš„æ•°æ®ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        info_print("ğŸ“– åŠ è½½RAGæ ·æœ¬æ•°æ®...")
        
        # ä½¿ç”¨BM25Evaluatorçš„æ•°æ®åŠ è½½åŠŸèƒ½
        df = self.bm25_evaluator.load_and_process_data()
        if df is None:
            error_print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            return None
        
        info_print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} ä¸ªRAGæ ·æœ¬")
        return df
    
    def get_relevant_chunks_for_query(self, query: str, reference_contexts: List[str]) -> List[str]:
        """
        è·å–ä¸æŸ¥è¯¢ç›¸å…³çš„å‚è€ƒåˆ†å—
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            reference_contexts: å‚è€ƒåˆ†å—åˆ—è¡¨
            
        Returns:
            List[str]: ç›¸å…³åˆ†å—åˆ—è¡¨
        """
        if not query or not reference_contexts:
            return []
        
        relevant_chunks = []
        for chunk in reference_contexts:
            # ä½¿ç”¨BM25ç®—æ³•åˆ¤æ–­ç›¸å…³æ€§
            is_relevant, score = is_chunk_relevant(query, chunk, threshold=-10.0)  # ä½¿ç”¨è¾ƒä½çš„BM25é˜ˆå€¼
            if is_relevant:
                relevant_chunks.append(chunk)
        
        return relevant_chunks
    
    def get_ranked_chunks_for_query(self, query: str, retrieved_contexts: List[str]) -> List[Tuple[str, float]]:
        """
        è·å–æŒ‰ç›¸å…³æ€§æ’åºçš„æ£€ç´¢åˆ†å—
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            retrieved_contexts: æ£€ç´¢åˆ†å—åˆ—è¡¨
            
        Returns:
            List[Tuple[str, float]]: æ’åºåçš„åˆ†å—åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(åˆ†å—å†…å®¹, ç›¸å…³æ€§åˆ†æ•°)
        """
        if not query or not retrieved_contexts:
            return []
        
        # ä½¿ç”¨BM25ç®—æ³•å¯¹æ£€ç´¢åˆ†å—è¿›è¡Œæ’åº
        ranked_chunks = find_relevant_chunks(
            query=query,
            chunks=retrieved_contexts,
            max_chunks=len(retrieved_contexts),
            threshold=-10.0  # ä½¿ç”¨è¾ƒä½çš„é˜ˆå€¼ä»¥åŒ…å«æ‰€æœ‰åˆ†å—
        )
        
        return ranked_chunks
    
    def calculate_relevance_scores(self, query: str, retrieved_contexts: List[str], 
                                 reference_contexts: List[str]) -> List[float]:
        """
        è®¡ç®—æ£€ç´¢åˆ†å—çš„ç›¸å…³æ€§åˆ†æ•°
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            retrieved_contexts: æ£€ç´¢åˆ†å—åˆ—è¡¨
            reference_contexts: å‚è€ƒåˆ†å—åˆ—è¡¨
            
        Returns:
            List[float]: æ¯ä¸ªæ£€ç´¢åˆ†å—çš„ç›¸å…³æ€§åˆ†æ•°
        """
        if not retrieved_contexts or not reference_contexts:
            return []
        
        relevance_scores = []
        for retrieved_chunk in retrieved_contexts:
            max_relevance = 0.0
            for ref_chunk in reference_contexts:
                # ä½¿ç”¨BM25Evaluatorçš„ç›¸å…³æ€§è®¡ç®—æ–¹æ³•
                relevance = self.bm25_evaluator.calculate_relevance_score(retrieved_chunk, ref_chunk)
                if relevance > max_relevance:
                    max_relevance = relevance
            
            # å°†ç›¸å…³æ€§åˆ†æ•°è½¬æ¢ä¸ºäºŒè¿›åˆ¶ç›¸å…³æ€§ï¼ˆ0æˆ–1ï¼‰
            binary_relevance = 1.0 if max_relevance > self.relevance_threshold else 0.0
            relevance_scores.append(binary_relevance)
        
        return relevance_scores
    
    def calculate_dcg(self, relevance_scores: List[float]) -> float:
        """
        è®¡ç®—DCG (Discounted Cumulative Gain)
        ä½¿ç”¨å€’åºä½ç½®è®¡ç®—ï¼Œä½†ä¿æŒNDCGè¯„ä¼°é€»è¾‘ï¼šç›¸å…³åˆ†å—è¶Šé å‰å¾—åˆ†è¶Šé«˜
        
        Args:
            relevance_scores: ç›¸å…³æ€§åˆ†æ•°åˆ—è¡¨
            
        Returns:
            float: DCGå€¼
        """
        if not relevance_scores:
            return 0.0
        
        dcg = 0.0
        for i, relevance in enumerate(relevance_scores):
            # å€’åºä½ç½®è®¡ç®—ï¼šindex=0â†’ä½ç½®3, index=1â†’ä½ç½®2, index=2â†’ä½ç½®1
            # ä½†NDCGè¯„ä¼°ä»ç„¶éµå¾ª"ç›¸å…³åˆ†å—è¶Šé å‰å¾—åˆ†è¶Šé«˜"çš„åŸåˆ™
            position = len(relevance_scores) - i
            # DCGå…¬å¼: DCG = Î£(2^relevance - 1) / log2(position + 1)
            dcg += (2**relevance - 1) / np.log2(position + 1)
        
        return dcg
    
    def calculate_idcg(self, relevance_scores: List[float]) -> float:
        """
        è®¡ç®—IDCG (Ideal Discounted Cumulative Gain)
        
        Args:
            relevance_scores: ç›¸å…³æ€§åˆ†æ•°åˆ—è¡¨
            
        Returns:
            float: IDCGå€¼
        """
        if not relevance_scores:
            return 0.0
        
        # å°†ç›¸å…³æ€§åˆ†æ•°æŒ‰é™åºæ’åˆ—ï¼ˆç†æƒ³æ’åºï¼‰
        ideal_scores = sorted(relevance_scores, reverse=True)
        
        # è®¡ç®—ç†æƒ³æ’åºçš„DCGï¼Œä½¿ç”¨æ­£å‘ä½ç½®
        idcg = 0.0
        for i, relevance in enumerate(ideal_scores):
            position = i + 1  # ç†æƒ³æ’åºä¸­ï¼Œä½ç½®å°±æ˜¯i+1
            # DCGå…¬å¼: DCG = Î£(2^relevance - 1) / log2(position + 1)
            idcg += (2**relevance - 1) / np.log2(position + 1)
        
        return idcg
    
    def calculate_ndcg(self, query: str, retrieved_contexts: List[str], 
                      reference_contexts: List[str]) -> Tuple[float, Dict[str, Any]]:
        """
        è®¡ç®—å•ä¸ªæŸ¥è¯¢çš„NDCG
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            retrieved_contexts: æ£€ç´¢åˆ†å—åˆ—è¡¨
            reference_contexts: å‚è€ƒåˆ†å—åˆ—è¡¨
            
        Returns:
            Tuple[float, Dict[str, Any]]: (NDCGå€¼, è¯¦ç»†è®¡ç®—è¿‡ç¨‹)
        """
        if not retrieved_contexts or not reference_contexts:
            return 0.0, {
                'relevance_scores': [],
                'dcg': 0.0,
                'idcg': 0.0,
                'ndcg': 0.0,
                'calculation_steps': []
            }
        
        # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        relevance_scores = self.calculate_relevance_scores(query, retrieved_contexts, reference_contexts)
        
        # è®¡ç®—DCG
        dcg = self.calculate_dcg(relevance_scores)
        
        # è®¡ç®—IDCG
        idcg = self.calculate_idcg(relevance_scores)
        
        # è®¡ç®—NDCG
        if idcg > 0:
            ndcg = dcg / idcg
        else:
            ndcg = 0.0
        
        # ç”Ÿæˆè®¡ç®—æ­¥éª¤
        calculation_steps = []
        for i, (chunk, relevance) in enumerate(zip(retrieved_contexts, relevance_scores)):
            # å€’åºä½ç½®è®¡ç®—ï¼šindex=0â†’ä½ç½®3, index=1â†’ä½ç½®2, index=2â†’ä½ç½®1
            position = len(retrieved_contexts) - i
            gain = 2**relevance - 1
            discount = np.log2(position + 1)
            dcg_contribution = gain / discount
            
            calculation_steps.append({
                'position': position,
                'chunk': chunk,
                'relevance': relevance,
                'gain': gain,
                'discount': discount,
                'dcg_contribution': dcg_contribution
            })
        
        return ndcg, {
            'relevance_scores': relevance_scores,
            'dcg': dcg,
            'idcg': idcg,
            'ndcg': ndcg,
            'calculation_steps': calculation_steps,
            'total_chunks': len(retrieved_contexts),
            'relevant_chunks': sum(relevance_scores)
        }
    
    def evaluate_ndcg(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        è®¡ç®—NDCGæŒ‡æ ‡
        
        Args:
            df: å¤„ç†åçš„æ•°æ®
            
        Returns:
            Dict[str, Any]: NDCGè¯„ä¼°ç»“æœ
        """
        info_print("ğŸ” å¼€å§‹NDCGè¯„ä¼°...")
        info_print("ğŸ“‹ è¯„ä¼°é€»è¾‘:")
        info_print("  â€¢ NDCG = DCG / IDCG")
        info_print("  â€¢ DCG = Î£(2^relevance - 1) / log2(position + 1)")
        info_print("  â€¢ IDCG = ç†æƒ³æ’åºä¸‹çš„DCGå€¼")
        info_print(f"  â€¢ ç›¸å…³æ€§åˆ¤æ–­: æ£€ç´¢åˆ†å—ä¸å‚è€ƒåˆ†å—çš„è¯­ä¹‰ç›¸ä¼¼åº¦ > {self.relevance_threshold}")
        info_print()
        
        results = {
            'ndcg_scores': [],
            'detailed_results': [],
            'total_queries': 0,
            'queries_with_relevant_chunks': 0,
            'queries_without_relevant_chunks': 0
        }
        
        # è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„NDCG
        for idx, row in df.iterrows():
            user_input = str(row['user_input']) if pd.notna(row['user_input']) else ""
            retrieved_contexts = row['retrieved_contexts']
            reference_contexts = row['reference_contexts']
            
            if not retrieved_contexts or not reference_contexts:
                # å¯¹äºç©ºæ£€ç´¢ç»“æœï¼ŒNDCGä¸º0
                results['ndcg_scores'].append(0.0)
                results['total_queries'] += 1
                results['queries_without_relevant_chunks'] += 1
                results['detailed_results'].append({
                    'row_index': idx,
                    'user_input': user_input,
                    'ndcg': 0.0,
                    'dcg': 0.0,
                    'idcg': 0.0,
                    'retrieved_count': len(retrieved_contexts) if retrieved_contexts else 0,
                    'reference_count': len(reference_contexts) if reference_contexts else 0,
                    'relevant_chunks_count': 0,
                    'calculation_details': {
                        'relevance_scores': [],
                        'dcg': 0.0,
                        'idcg': 0.0,
                        'ndcg': 0.0,
                        'calculation_steps': []
                    }
                })
                continue
            
            # è®¡ç®—NDCG
            ndcg, calculation_details = self.calculate_ndcg(
                user_input, retrieved_contexts, reference_contexts
            )
            
            results['ndcg_scores'].append(ndcg)
            results['total_queries'] += 1
            
            if ndcg > 0:
                results['queries_with_relevant_chunks'] += 1
            else:
                results['queries_without_relevant_chunks'] += 1
            
            # è¯¦ç»†ç»“æœ
            results['detailed_results'].append({
                'row_index': idx,
                'user_input': user_input,
                'ndcg': ndcg,
                'dcg': calculation_details['dcg'],
                'idcg': calculation_details['idcg'],
                'retrieved_count': len(retrieved_contexts),
                'reference_count': len(reference_contexts),
                'relevant_chunks_count': calculation_details['relevant_chunks'],
                'calculation_details': calculation_details
            })
        
        # æŒ‰æ ·æœ¬åˆ†ç»„æ˜¾ç¤ºç»“æœ
        info_print("\n" + "=" * 80)
        info_print("ğŸ“Š æ ·æœ¬NDCGè¯„ä¼°ç»“æœ")
        info_print("=" * 80)
        
        for result in results['detailed_results']:
            sample_idx = result['row_index'] + 1
            user_input = result['user_input']
            ndcg = result['ndcg']
            dcg = result['dcg']
            idcg = result['idcg']
            retrieved_count = result['retrieved_count']
            reference_count = result['reference_count']
            relevant_count = result['relevant_chunks_count']
            details = result['calculation_details']
            
            info_print(f"\nğŸ“‹ æ ·æœ¬ {sample_idx}:")
            info_print(f"  æŸ¥è¯¢: {user_input}")
            info_print(f"  æ£€ç´¢åˆ†å—æ•°: {retrieved_count}ä¸ª, å‚è€ƒåˆ†å—æ•°: {reference_count}ä¸ª")
            info_print(f"  ç›¸å…³åˆ†å—æ•°: {relevant_count}ä¸ª")
            
            if ndcg > 0:
                info_print(f"  ğŸ“Š NDCGå¾—åˆ†: {ndcg:.4f}")
                info_print(f"  ğŸ“Š DCG: {dcg:.4f}")
                info_print(f"  ğŸ“Š IDCG: {idcg:.4f}")
                
                # æ˜¾ç¤ºè®¡ç®—è¿‡ç¨‹
                if details['calculation_steps']:
                    info_print(f"  ğŸ“ˆ è®¡ç®—è¿‡ç¨‹:")
                    for step in details['calculation_steps']:
                        status = "âœ… ç›¸å…³" if step['relevance'] > 0 else "âŒ ä¸ç›¸å…³"
                        info_print(f"    ä½ç½®{step['position']}: {status} (ç›¸å…³æ€§: {step['relevance']:.0f})")
                        info_print(f"      å¢ç›Š: 2^{step['relevance']:.0f} - 1 = {step['gain']:.0f}")
                        info_print(f"      æŠ˜æŸ: log2({step['position'] + 1}) = {step['discount']:.4f}")
                        info_print(f"      DCGè´¡çŒ®: {step['dcg_contribution']:.4f}")
                        info_print(f"      åˆ†å—: {step['chunk'][:100]}...")
                        info_print()
                
                # æ˜¾ç¤ºç›¸å…³æ€§åˆ†æ•°åºåˆ—
                relevance_scores = details['relevance_scores']
                info_print(f"  ğŸ¯ ç›¸å…³æ€§åˆ†æ•°åºåˆ—: {[f'{score:.0f}' for score in relevance_scores]}")
            else:
                info_print(f"  âŒ æ— ç›¸å…³åˆ†å—")
                info_print(f"  ğŸ“Š NDCGå¾—åˆ†: 0.0000")
        
        # è®¡ç®—å¹³å‡NDCG
        if results['ndcg_scores']:
            results['avg_ndcg'] = np.mean(results['ndcg_scores'])
        else:
            results['avg_ndcg'] = 0.0
        
        info_print(f"\nâœ… NDCGè¯„ä¼°å®Œæˆ")
        info_print(f"ğŸ“Š å¹³å‡NDCG: {results['avg_ndcg']:.4f}")
        info_print(f"ğŸ“Š æ€»æŸ¥è¯¢æ•°: {results['total_queries']}")
        info_print(f"ğŸ“Š æœ‰ç›¸å…³åˆ†å—çš„æŸ¥è¯¢æ•°: {results['queries_with_relevant_chunks']}")
        info_print(f"ğŸ“Š æ— ç›¸å…³åˆ†å—çš„æŸ¥è¯¢æ•°: {results['queries_without_relevant_chunks']}")
        
        return results
    
    def print_detailed_analysis(self, results: Dict[str, Any]):
        """
        æ‰“å°è¯¦ç»†çš„NDCGåˆ†æç»“æœ
        
        Args:
            results: NDCGè¯„ä¼°ç»“æœ
        """
        info_print("\n" + "=" * 80)
        info_print("ğŸ“Š NDCGè¯¦ç»†åˆ†æ")
        info_print("=" * 80)
        
        info_print("ğŸ“‹ NDCGæŒ‡æ ‡è¯´æ˜:")
        info_print("  â€¢ NDCG (Normalized Discounted Cumulative Gain) = å½’ä¸€åŒ–æŠ˜æŸç´¯ç§¯å¢ç›Š")
        info_print("  â€¢ DCG = Î£(2^relevance - 1) / log2(position + 1)")
        info_print("  â€¢ IDCG = ç†æƒ³æ’åºä¸‹çš„DCGå€¼")
        info_print("  â€¢ NDCG = DCG / IDCG")
        info_print("  â€¢ å¦‚æœæ²¡æœ‰ç›¸å…³åˆ†å—ï¼ŒNDCGä¸º0")
        info_print(f"  â€¢ ç›¸å…³æ€§é˜ˆå€¼: {self.relevance_threshold}")
        info_print()
        
        info_print("ğŸ“Š è¯„ä¼°ç»“æœ:")
        info_print(f"1. å¹³å‡NDCG: {results['avg_ndcg']:.4f} ({results['avg_ndcg']*100:.1f}%)")
        info_print(f"2. æ€»æŸ¥è¯¢æ•°: {results['total_queries']}")
        info_print(f"3. æœ‰ç›¸å…³åˆ†å—çš„æŸ¥è¯¢æ•°: {results['queries_with_relevant_chunks']}")
        info_print(f"4. æ— ç›¸å…³åˆ†å—çš„æŸ¥è¯¢æ•°: {results['queries_without_relevant_chunks']}")
        
        if results['total_queries'] > 0:
            coverage = results['queries_with_relevant_chunks'] / results['total_queries']
            info_print(f"5. ç›¸å…³åˆ†å—è¦†ç›–ç‡: {coverage:.4f} ({coverage*100:.1f}%)")
        
        # NDCGåˆ†å¸ƒç»Ÿè®¡
        ndcg_scores = results['ndcg_scores']
        if ndcg_scores:
            info_print(f"\nğŸ“Š NDCGåˆ†å¸ƒ:")
            info_print(f"  â€¢ å¹³å‡NDCG: {np.mean(ndcg_scores):.4f}")
            info_print(f"  â€¢ æœ€é«˜NDCG: {np.max(ndcg_scores):.4f}")
            info_print(f"  â€¢ æœ€ä½NDCG: {np.min(ndcg_scores):.4f}")
            info_print(f"  â€¢ æ ‡å‡†å·®: {np.std(ndcg_scores):.4f}")
    
    def print_sample_analysis(self, results: Dict[str, Any]):
        """
        æŒ‰æ ·æœ¬æ‰“å°NDCGåˆ†æç»“æœï¼Œæ˜¾ç¤ºæ¯ä¸ªæ ·æœ¬çš„åˆ†å—è®¡ç®—è¿‡ç¨‹
        
        Args:
            results: NDCGè¯„ä¼°ç»“æœ
        """
        info_print("\n" + "=" * 80)
        info_print("ğŸ“Š æ ·æœ¬çº§åˆ«NDCGåˆ†æ")
        info_print("=" * 80)
        
        # æ˜¾ç¤ºæ‰€æœ‰æ ·æœ¬çš„è¯¦ç»†è®¡ç®—è¿‡ç¨‹
        for i, result in enumerate(results['detailed_results'], 1):
            info_print(f"\nğŸ“‹ æ ·æœ¬ {i} (è¡Œ {result['row_index'] + 1}):")
            info_print(f"  æŸ¥è¯¢: {result['user_input']}")
            info_print(f"  æ£€ç´¢åˆ†å—æ•°: {result['retrieved_count']}ä¸ª, å‚è€ƒåˆ†å—æ•°: {result['reference_count']}ä¸ª")
            info_print(f"  ç›¸å…³åˆ†å—æ•°: {result['relevant_chunks_count']}ä¸ª")
            info_print(f"  DCG: {result['dcg']:.4f}, IDCG: {result['idcg']:.4f}, NDCG: {result['ndcg']:.4f}")
            
            # æ˜¾ç¤ºåˆ†å—è®¡ç®—è¿‡ç¨‹
            if 'calculation_details' in result and 'calculation_steps' in result['calculation_details']:
                info_print(f"\n  ğŸ“Š åˆ†å—è®¡ç®—è¿‡ç¨‹:")
                calculation_steps = result['calculation_details']['calculation_steps']
                for step in calculation_steps:
                    status = "âœ… ç›¸å…³" if step['relevance'] > 0 else "âŒ ä¸ç›¸å…³"
                    info_print(f"    ä½ç½®{step['position']}: {status}")
                    info_print(f"      åˆ†å—å†…å®¹: {step['chunk'][:80]}...")
                    info_print(f"      ç›¸å…³æ€§åˆ†æ•°: {step['relevance']:.4f}")
                    info_print(f"      Gain: {step['gain']:.4f}")
                    info_print(f"      Discount: {step['discount']:.4f}")
                    info_print(f"      DCGè´¡çŒ®: {step['dcg_contribution']:.4f}")
                    info_print()
            else:
                info_print(f"  ğŸ“Š æ— åˆ†å—è®¡ç®—è¿‡ç¨‹")
            
            info_print(f"  {'='*60}")
        
        # æŒ‰NDCGæ’åºæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        sorted_results = sorted(
            results['detailed_results'], 
            key=lambda x: x['ndcg'], 
            reverse=True
        )
        
        info_print(f"\nğŸ” è¡¨ç°æœ€å¥½çš„æ ·æœ¬ (å‰3ä¸ª):")
        for i, result in enumerate(sorted_results[:3], 1):
            info_print(f"  {i}. è¡Œ {result['row_index'] + 1}: NDCG {result['ndcg']:.4f}")
            info_print(f"     æŸ¥è¯¢: {result['user_input'][:100]}...")
            info_print(f"     ç›¸å…³åˆ†å—æ•°: {result['relevant_chunks_count']}ä¸ª")
        
        info_print(f"\nğŸ”» è¡¨ç°æœ€å·®çš„æ ·æœ¬ (å3ä¸ª):")
        for i, result in enumerate(sorted_results[-3:], 1):
            info_print(f"  {i}. è¡Œ {result['row_index'] + 1}: NDCG {result['ndcg']:.4f}")
            info_print(f"     æŸ¥è¯¢: {result['user_input'][:100]}...")
            info_print(f"     ç›¸å…³åˆ†å—æ•°: {result['relevant_chunks_count']}ä¸ª")
    
    def run_evaluation(self) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„NDCGè¯„ä¼°
        
        Returns:
            Dict[str, Any]: NDCGè¯„ä¼°ç»“æœ
        """
        info_print("ğŸš€ å¼€å§‹NDCG RAGè¯„ä¼°")
        info_print("=" * 60)
        
        try:
            # 1. åŠ è½½æ•°æ®
            df = self.load_and_process_data()
            if df is None:
                return {"error": "æ•°æ®åŠ è½½å¤±è´¥"}
            
            # 2. è¿è¡ŒNDCGè¯„ä¼°
            results = self.evaluate_ndcg(df)
            
            # 3. æ‰“å°ç»“æœ
            self.print_detailed_analysis(results)
            self.print_sample_analysis(results)
            
            return results
            
        except Exception as e:
            error_print(f"âŒ NDCGè¯„ä¼°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {"error": str(e)}


def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºé…ç½®
    config = EvaluationConfig(
        api_key=os.getenv("QWEN_API_KEY", "dummy_key"),
        api_base=os.getenv("QWEN_API_BASE", "dummy_base")
    )
    
    # åˆ›å»ºNDCGè¯„ä¼°å™¨å¹¶è¿è¡Œè¯„ä¼°
    evaluator = NDCGEvaluator(config)
    results = evaluator.run_evaluation()
    
    if "error" in results:
        error_print(f"âŒ NDCGè¯„ä¼°å¤±è´¥: {results['error']}")
    else:
        info_print(f"\nğŸ‰ NDCGè¯„ä¼°æˆåŠŸå®Œæˆï¼")
        info_print(f"ğŸ“Š æœ€ç»ˆNDCGåˆ†æ•°: {results['avg_ndcg']:.4f}")


if __name__ == "__main__":
    main()
